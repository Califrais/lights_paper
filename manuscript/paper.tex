\documentclass[11pt]{article}

\usepackage{xcolor}
\definecolor{darkpastelgreen}{rgb}{0.01, 0.75, 0.24}

\usepackage[colorlinks=true,
            linkcolor=red,
            urlcolor=darkpastelgreen,
            citecolor=blue,
            breaklinks=true]{hyperref}
\usepackage{breakurl} 
\usepackage[a4paper, left=3cm, right=3cm, top=3cm, bottom=3cm]{geometry}
\RequirePackage{amsmath,amsfonts, amssymb,amsthm}

\hypersetup{pdfauthor = {Simon Bussy}}

\usepackage{authblk}
\title{\vspace{-.5cm} Lights: a generalized joint model for high-dimensional multivariate longitudinal data and censored durations \vspace{.5cm}}
\author[1,2]{Simon Bussy\thanks{Corresponding author: \href{mailto:simon.bussy@gmail.com}{\texttt{simon.bussy@gmail.com}}}}
\author[2,3]{Van Tuan Nguyen}
\author[4]{Antoine Barbieri}
\author[1]{Sarah Zohar}
\author[1,5]{Anne-Sophie Jannot}
\affil[1]{INSERM, UMRS 1138, Centre de Recherche des Cordeliers, Paris, France}
\affil[2]{LOPF, Califrais' Machine Learning Lab, Paris, France}
\affil[3]{LPSM, UMR 8001, CNRS, Sorbonne University, Paris, France}
\affil[4]{INSERM, UMR 1219, Bordeaux Population Health Research Center, Univ. Bordeaux, France}
\affil[5]{Biomedical Informatics and Public Health Department, EGPH, APHP, Paris, France}
\setcounter{Maxaffil}{0}
\renewcommand\Affilfont{\itshape\small}

\usepackage{mathtools}
\usepackage{mathrsfs}
\usepackage{mathrsfs} 
\usepackage{natbib}
\usepackage{setspace}
\usepackage{dsfont}
\usepackage{caption}
\usepackage{booktabs}
\usepackage{subfigure}
\usepackage{bm}
\usepackage{tikz}
\usetikzlibrary{fit,shapes,shadows,arrows,positioning,graphs}
\usepackage{algpseudocode}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\newcommand\mycommfont[1]{\footnotesize\ttfamily\textcolor{orange}{#1}}
\SetCommentSty{mycommfont}
\SetKwInput{KwInput}{Input} 
\SetKwInput{KwOutput}{Output}

\newtheorem{assumption}{Assumption}{\bf}{\rm} 
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}

\DeclareMathOperator{\argmin}{argmin}
\DeclareMathOperator{\Tr}{Tr}

\newcommand{\dd}{\mathrm{d}}
\newcommand{\ind}[1]{\mathds{1}_{#1}}
\newcommand{\norm}[1]{\|#1\|}
\newcommand{\cY}{\mathcal Y}
\newcommand{\cD}{\mathcal D}
\newcommand{\cC}{\mathcal C}
\newcommand{\cG}{\mathcal G}
\newcommand{\cN}{\mathcal N}
\newcommand{\cA}{\mathcal A}
\newcommand{\cQ}{\mathcal Q}
\newcommand{\cU}{\mathcal U}
\newcommand{\cR}{\mathcal R}
\newcommand{\cH}{\mathcal H}
\newcommand{\cB}{\mathcal B}
\newcommand{\cS}{\mathcal S}
\newcommand{\cI}{\mathcal I}
\newcommand{\R}{\mathds R}
\newcommand{\N}{\mathds N}
\newcommand{\E}{\mathds E}
\renewcommand{\P}{\mathds P}
\newcommand{\bSigma}{\textbf{$\Sigma$}}

\date{}

\begin{document}

\maketitle

\vspace{-.5cm}

\begin{abstract}

This paper introduces a prognostic method called \textit{lights} to deal with the problem of joint modeling of longitudinal data and censored durations, where a large number of both longitudinal and time-independent features are available. 
In the literature, standard joint models are either of type shared random-effect or joint latent class ones ; where the association structure between the longitudinal and the time-to-event submodels takes respectively the form of either shared association features learned from the longitudinal processes and included as potential risk factor in the survival model, or latent classes modeling population heterogeneity.
We pick modeling ideas from both worlds and use appropriate penalties during inference for being able to learn from a high-dimensional context.
The statistical performance of the method is examined on an extensive Monte Carlo simulation study, and finally illustrated on a publicly available dataset.
Our proposed method significantly outperforms the state-of-the-art joint models regarding risk prediction in terms of C-index in a so-called real-time prediction paradigm, with a computing time orders of magnitude faster. In addition, it provides powerful interpretability by automatically pinpointing significant features being relevant from a practical perspective. Thus, we propose a powerfull tool with the ability of automatically determining significant prognostic longitudinal features, which is of increasing importance in many areas: for instance personalized medicine, or churn prediction in a customer profile and activity monitoring setting, to name but a few.\\

\noindent
\emph{Keywords.} High-dimensional estimation; Joint modeling; Multivariate longitudinal data; Survival analysis
\end{abstract}

\section{Introduction}

With the increasing expectations to know their customers from account opening throughout the duration of the business relationship, web companies have the luxury of building elaborate systems to help them keep everything on track. The amount of recorded data per client is often tremendous and growing through time. There is no tool today to take into account simultaneously a huge number of longitudinal signals in a high-dimensional context to perform real-time churn (or satisfaction) risk prediction.
Similarly, in many clinical studies, it has become increasingly common to record the values of longitudinal features (e.g., biomarkers) until the occurrence of an event of interest for a subject. The ``joint modeling'' approaches, namely modeling the longitudinal and survival outcomes through a joint likelihood model rather than separately, has received considerable attention during the past two decades~\citep{tsiatis2004joint}. Numerical studies suggest that these approaches are among the most satisfactory to combine information~\citep{yu2004joint}. They have the advantage of making more efficient use of the data since information about survival also goes into modeling the longitudinal features. In addition, they produce unbiased estimates and do not rely on approximations for incorporating conplex longitudinal trajectories. Most developments have either focused on shared random-effect models (SREMs)~\citep{wulfsohn1997joint}, in which characteristics of the longitudinal processes (for instance functions of the random effects) are included as features in the survival model ; or on joint latent class models (JLCMs)~\citep{vermunt2003latent}, in which the population is considered as heterogeneous, with the assumption that there exist homogeneous latent classes sharing the same marker trajectories and the same prognostic.

\paragraph{The high-dimensional longitudinal data context.}
With the exploding number of daily internet users, or with the development of electronic health records in a medical context, high-dimensional settings are becoming increasingly frequent in various contexts where the number of available features to consider as potential risk factors is tremendous.
Moreover, with an increased focus on personalised medicine, the need to implement multivariate models that account for a large number of longitudinal outcomes is critical. Despite this, joint models have predominantly focused on univariate data, with attempts to fit multiple univariate joint models separately~\citep{wang2012joint}, which is inefficient~\citep{lin2002maximum}. 
Despite many multivariate models being presented in full generality, questions arrising from the high-dimensional context -- e.g., computational power, limits in numerical estimation, or sample size -- are never considered in analyses (to the best of our knowledge), and the number of longitudinal outcomes considered in numerical studies are often very low (see~\citet{hickey2016joint} for a complete review). For instance,~\citet{jaffa2014joint} only considers 3 longitudinal outcomes in the simulation study while mentioning a ``high-dimensional multivariate longitudinal data'' context.


\paragraph{General framework.}

The setting of this paper is such that we want to incorporate high-dimensional time-dependent (longitudinal) features measured with error in a survival model. Let us consider the usual survival analysis framework.
Following~\citet{andersen2012statistical}, let non-negative random variables $T^\star$ and $C$ stand for the times of the event of interest and censoring times respectively. The event of interest could be for instance the time when a client stops using a company's product or service in a churn prediction setting~ ; or survival time, re-hospitalization, relapse or disease progression in a medical context.
We then denote $T$ the right-censored time and $\Delta$ the censoring indicator, defined as 
\begin{equation*}
T = T^\star \wedge C \quad \text{and} \quad \Delta = \ind{\{T^\star \leq C\}}
\end{equation*}
respectively, where $a \wedge b$ denotes the minimum between two numbers $a$ and $b$, and $\ind{\{\cdot\}}$ the indicator function taking the value $1$ if the condition in $\{\cdot\}$ is satisfied and $0$ otherwise.

Let $X$ denotes the $p$-dimensional vector of time-independent features (e.g., patients characteristics, therapeutic strategy, or omics features recorded at the begining of a medical study), and let  $Y(t) = \big(Y^1(t), \ldots, Y^L(t) \big)^\top \in \R^L$ denote the value of the $L$-dimensional longitudinal outcome at time point $t \geq 0$, with $L \in \N_+$.

\paragraph{Heterogeneity of the population.}

An assumption of heterogeneity within the subject population is frequently relevant in medical research where several differing profiles of subjects are expected~\citep{bussy2019c}. To take account of this, we introduce a latent variable $G \in \{0, \ldots, K-1\}$ modeling the $K \geq 1$ classes of different risk, which is a classical modeling assumption in JLCMs~\citep{lin2002latent, proust2014joint}. Let us denote
\begin{equation}
  \label{eq:pi}
  \pi_{\xi_k}(x) = \P[G=k|X=x]
\end{equation}
the latent class membership probability given time-independent features $x \in \R^p$, and consider a softmax link function given by
\begin{equation}
  \label{eq:pi-softmax} 
  \pi_{\xi_k}(x) = \dfrac{e^{x^\top\xi_k}}{\sum_{k=0}^{K-1}e^{x^\top\xi_k}}
\end{equation}
where $\xi_k \in \R^p$ denotes a vector of coefficients that quantifies the impact of each time-independent features on the probability that a subject belongs to the $k$-th latent class, with $\xi_0 = \mathbf{0}_p$ for overparameterization purpose, where $\mathbf{0}_p$ stands for the vector of $\R^p$ having all coordinates equal to zero. The intercept term is here omitted without loss of generality. 
From now on, all computations are done conditionally on features $x$.

\paragraph{Main contribution.} 

In this paper, we propose a method called \textit{lights} (generaLized joInt hiGH-dimensional longiTudinal Survival) which is inspired by both JLCMs and SREMs, since we also include features extracted from the longitudinal processes as potential risk factor in the survival model, which is a class-specific Cox model~\citep{Cox1972JRSS} with high-dimensional shared associations.
To allow flexibility in modeling the dependency between the longitudinal features and the event time, we use appropriate penalties : elastic net~\citep{zou2005regularization}
for time-independent feature selection in the latent class membership, and sparse group lasso~\citep{simon2013sparse} in the survival model : this penalty acts like the lasso at the trajectory level, namely an entire trajectory may drop out of the model, and yields sparsity for a given trajectory.
Inference is achieved using an efficient and novel proximal Quasi-Newton Expectation Maximization algorithm (prox-QNEM).
Posterior estimates of the latent class membership probabilities given the longitudinal process and the fact that the subject is still alive at prediction time -- in a so called ``real-time prediction paradigm'' -- are then used as discriminative marker rule for risk prediction in the cross-validation procedure for selecting the best regularization hyper-parameters.
Hence, the method provides interpretations of the high-dimensional longitudinal features, thus offering a powerful tool for real-time decision support in a customer's satisfaction monitoring context for instance, or else for clinical decision making in patient monitoring.

\paragraph{Organization of the paper.}

A precise description of the model is given in Section~\ref{sec:Method}.
Section~\ref{sec:inference} focuses on a regularized version of the
model to exploit dimension reduction and prevent overfitting. Inference is
presented under this framework, as well as the developed algorithm.
Section~\ref{sec:Performance evaluation} introduces the C-index metric, as well as a novel evaluation strategy to assess diagnostic prediction performances while mimicking a real-time use of the model in clinical care, and finally the considered competing methods.
Section~\ref{sec:simulation study} presents the simulation procedure used to evaluate the performance of our method in a high-dimensional context and compares it with state-of-the-art ones. In Section~\ref{sec:application}, we apply our method to a publicly available dataset. Finally, we discuss the obtained results in Section~\ref{sec:conclusion}.

\paragraph{Notations.}

Throughout the paper, for every $q > 0,$ we denote by $\norm{v}_q$ the usual $\ell_q$-quasi norm of a vector $v \in \R^m,$ namely $\norm{v}_q =(\sum_{k=1}^m|v_k|^q)^{1/q}$. We also denote $\norm{v}_0 = |\{k : v_k \neq 0\}|$, where $|A|$ stands for the cardinality of a finite set $A$. $\lfloor a \rfloor$ denotes the largest integer less than or equal to $a \in \R$.
For $u, v \in \R^m$, we denote by $u \odot v$ the Hadamard product $u\odot v =(u_1v_1, \ldots, u_mv_m)^\top.$ 
For a squared matrix $M$, $\text{vech}(M)$ stacks columns of $M$ one under another in a single vector, starting each column at its diagonal element. We write $I_m$ for the identity matrix of $\R^{m \times m}$.
Finally, we write, for short, $\mathbf{1}_m$  (resp. $\mathbf{0}_m$) for the vector of $\R^m$ having all coordinates equal to one (resp. zero).


\section{Method}
\label{sec:Method}

In this section, we descibe the longitudinal and time-to-event submodels, as well as the required hypothesis in order to write a likelihood and draw inference for the lights model.

\subsection{Class-specific marker trajectories}

We suppose a class-specific marker trajectory and a generalized linear mixed model for each longitudinal marker given latent class $G$, so that for the $l$-th outcome at time $t \geq 0$ one has
\begin{equation}
  \label{eq:link-function}
  h_l\big(\E[Y^l(t)|b^l, G=k]\big) = m_k^l(t)
 \end{equation}
where $h_l$ denotes a known one-to-one link function, and $m_k^l$ the linear predictor such that
\[ m_k^l(t) = u^l(t)^\top\beta_k^l + v^l(t)^\top b^l \]
where $u^l(t) \in \R^{q_l}$ is a row vector of (possibly) time-varying features with corresponding unknown fixed effect parameters $\beta_k^l$, and $v^l(t) \in \R^{r_l}$ is a row vector of (possibly) time-varying features with $r_l \leq q_l$.
A suitable distributional assumption for the random effects component is a zero-mean multivariate normal distribution~\citep{hickey2016joint}, that is
\begin{equation}
   \label{eq:random-effect-law}
   b^l \sim \cN(0, D_{ll})
 \end{equation} 
with $D_{ll} \in \R^{r_l \times r_l}$ the unstructured variance-covariance matrix. 
To account for dependence between the different longitudinal outcome types, we let $\text{Cov}[b^l,b^{l'}] = D_{ll'}$ for $l \ne l'$ and we denote
\[ D = 
\begin{bmatrix}
  D_{11} & \cdots & D_{1L}\\
  \vdots &  \ddots & \vdots \\
  D_{1L}^\top & \cdots & D_{LL}
\end{bmatrix}
\]
the global variance-covariance matrix.
In the sequel of the paper, our aim is to associate the true and unobserved value $m_k^l(t)$ of the $l$-th longitudinal outcome at time $t$ with the event outcome $T^\star$.

\subsection{Class-specific risk of event}

To quantify the effect of the longitudinal outcomes on the risk for an event, we use a Cox~\citep{Cox1972JRSS} relative risk model of the form
\begin{equation}
  \label{eq:intensity-model}
  \lambda(t|\cY(t), G = k) = \lambda_0(t) \exp \Big\{\sum_{l=1}^L \sum_{a=1}^\cA {\gamma_{k,a}^l} \Psi_a^l(t) \Big\},
\end{equation}
where $\lambda_0(\cdot)$ is an unspecified baseline hazard function and given that $G = k$, we denote 
\[\cY^l(t) = \{Y^l(u), 0 \leq u < t\} \quad \text{and} \quad \cY(t) = \bigcup_{l=1}^L \cY^l(t)\] 
the history of the true longitudinal process up to time $t$.
For each $l$-th longitudinal outcome, we consider $\cA \in \N_+$ known functionals $\Psi_a^l$ extracted from $\cY^l(t)$ through a given representation mapping, and $\gamma_{k,a}^l \in \R$ the corresponding joint representation parameters.  

Let us finally denote
\[\gamma_k= (\gamma_{k,1}^1, \ldots, \gamma_{k,\cA}^1, \ldots, \gamma_{k,1}^L, \ldots, \gamma_{k,\cA}^L )^\top \in \R^{L\cA}, \] so that
\begin{equation}
  \label{eq:def-asso-features}
  \lambda(t|\cY(t), G = k) = \lambda_0(t) \exp \big\{\gamma_k^\top \Psi(t) \big\},
\end{equation}
where $\Psi(t) \in \R^{L\cA}$ denotes the representation features vector.

\subsection{Generalization of SREMs and JLCMs}
 
Our model is clearly of JLCMs type, and can be viewed as a generalization of SREMs type in a much more flexible way. Table~\ref{table:shared_associations} gives common parameterizations for shared associations that are only considered separately ($\cA=1$) in SREMs.
\begin{table}[htb]
\centering
\begin{tabular}{cccc}
\toprule
Description & $\Psi_a^l(t, \beta_k^l, b^l)$  & Reference \\
\midrule
Linear predictor & $m_k^l(t)$ & \citet{chi2006joint} \\ [.15cm]
Random effects & $b^l$  & \citet{hatfield2011joint} \\
Time-dependent slope & $\dfrac{\dd}{\dd t} m_k^l(t)$ & \citet{rizopoulos2011bayesian} \\ [.3cm]
Cumulative effect & $\int_0^t m_k^l(s) \dd s$ & \citet{andrinopoulou2017combined} \\ [.1cm]
 \bottomrule
\end{tabular}
\caption[]{Examples of classical shared associations in SREMs.}
\label{table:shared_associations}
\end{table}

Our proposition differs from standard SREMs in two respects: $(i)$ representation vector $\Psi(t)$ does not depend on the modeling assumptions in the longitudinal submodel and $(ii)$ it allows to choose multiple high-dimensional representation mappings that characterize time series and concatenate them, since we perform features selection through the regularization strategy described in Section~\ref{sec:penalized-obj}. Point $(i)$ is key since for instance the $\beta_k^l$ dependence in $\Psi_a^l$ would lead to complicated updates, while the $b^l$ dependence would lead to untracktable integrals that are common in SREMs and require approximation methods such as Monte Carlo~\citep{hickey2018joinerml}, being computationally intensive and not scalable in a high-dimensional context. For point $(ii)$ in practice, we use the \texttt{Python} library \texttt{tsfresh}~\citep{christ2018time} and include many extracted features, such as absolute energy of the time series, statistics on autocorrelation, or Fourier and wavelet basis projections, to name but a few.

\subsection{Graphical model}
Figure~\ref{fig:graphical-model} below gives the graphical representation for the lights model to get a beter view of the dependence structure for the model.
\begin{figure}[!htb]
\centering
\resizebox{.9\textwidth}{!}{
\begin{tikzpicture}
\tikzstyle{main}=[circle, minimum size = 18mm, ultra thick, draw =black!80, node distance = 13mm,text centered]
\tikzstyle{var}=[rectangle, minimum size = 16mm, ultra thick, draw =black!80, node distance = 13mm,text centered]
\tikzstyle{connect}=[-latex, thick]
\tikzstyle{box}=[rectangle, draw=black!100]
  \node[var, fill = white!100] (beta) [] {\Large$\bm{\beta_k^l}$};
  \node[main, fill = white!100] (mu) [below=4cm of beta] {$\bm{M_{ik}^l(t)}$};
  \node[main, fill = black!30] (Y) [below=of mu] {\Large$\bm{Y_i^l(t)}$};
  \node[main, fill = white!100] (b) [left=of mu] {\Large$\bm{b_i^l}$};
  \node[var, fill = white!100] (phi) [left=of Y] {\Large$\bm{\phi_l}$};
  \node[var, fill = white!100] (Sigma) [above=of b] {\Large$\bm{D}$};
  \node[var, fill = white!100] (xi) [right=4.5cm of beta] {\Large$\bm{\xi_k}$};
  \node[var, fill = white!100] (gamma) [right=5cm of xi] {\Large$\bm{\gamma_k}$};
  \node[main, fill = white!100] (G) [below=4cm of xi] {\Large$\bm{G_i}$};
  \node[main, fill = white!100] (W) [right=8.5cm of Y] {\Large$\bm{\Psi_i(t)}$};
  \node[main, fill = white!100] (lambda) [below=4cm of gamma] {\Large$\bm{\lambda_i(t)}$};
  \node[main, fill = black!30] (T) [below=1.3cm of lambda] {\Large$\bm{T_i}$};
  \node[main, fill = black!30] (X) at (4, -3.3) {\Large$\bm{X_i}$};
  
  \path [->,draw,ultra thick, blue]
        (G) edge (mu)
        (Y) edge (W);
  \path [->,draw,ultra thick]
        (beta) edge (mu)
        (b) edge (mu)
        (mu) edge (Y)
        (Sigma) edge (b)
        (phi) edge (Y)
        (xi) edge (G)
        (X) edge (G)
        (gamma) edge (lambda)
        (W) edge (lambda)
        (G) edge (lambda)
        (lambda) edge (T)
        ;

  \node[rectangle, inner sep=8mm,draw=black!130, ultra thick, fit= (beta) (xi) (gamma),label={[anchor=west, yshift=-0.4cm, xshift=-8cm]{\Large$\bm{k = 1, \ldots,K}$}}] at (6.8,0.4) {};
  \node[rectangle, inner sep=4mm,draw=black!100, ultra thick, fit= (beta) (mu) (b) (Y) (Sigma) (phi)] at (-1.6,-4.5) {};
  \node[rectangle, inner sep=4mm, fit= (beta) (mu) (b) (Y) (Sigma) (phi),ultra thick, label={[anchor=west, yshift=-0.5cm, xshift=-2.8cm]{\Large$\bm{l = 1, \ldots,L}$}}] {};
  
  \node[rectangle,inner sep=6mm, draw=black!100, label=center:{\color{white}\Large{\textbf{Longitudinal}}}, minimum width=5cm, minimum height = 1cm, fill = black!50] at (-1.5,2.8) {};

  \node[rectangle,inner sep=6mm, draw=black!100,  label=center:{\color{white}\Large{\textbf{Time-independent}}}, minimum width=5cm, minimum height = 1cm, fill = black!50] at (5.2,2.8) {};

  \node[rectangle,inner sep=6mm, draw=black!100,  label=center:{\color{white}\Large{\textbf{Time-to-event}}}, minimum width=5cm, minimum height = 1cm, fill = black!50] at (12,2.8) {};
  
\end{tikzpicture}}
\caption{Graphical representation of the lights model. Square boxes denote observed data while circles denote unobserved (including random) terms. One can then observe the two links in blue between the submodels that gives rise to the joint model.}
\label{fig:graphical-model}
\end{figure}
 
\subsection{Likelihood}

Consider an independent and identically distributed (i.i.d.) cohort of $n$ subjects
\begin{equation}
  \label{eq:dataset-def}
  \cD_n = \big\{ (x_1, y_1^1, \ldots, y_1^L, t_1, \delta_1), \ldots, (x_n, y_n^1, \ldots, y_n^L, t_n, \delta_n) \big\}
\end{equation}
where for each subject $i=1, \ldots, n$, process $Y_i^l$ is measured $n_i^l$ times at $t_{i1}^l, \ldots, t_{in_i^l}^l$ (which can differ between subjects and outcomes) with $t_{ij}^l \leq t_{ij+1}^l$ for all $j=1, \ldots, n_i^l-1$ and such that
\begin{equation}
  \label{eq:def-yil}
  y_i^l=(y_{i1}^l, \ldots, y_{in_i^l}^l)^\top \in \R^{n_i^l} \quad \text{ with } \quad y_{ij}^l=Y_i^l(t_{ij}^l) 
\end{equation}
for all $l=1, \ldots, L$. 
For the $i$-th subject, let us denote 
\[
\left\{
    \begin{array}{ll}
        y_i &= ({y_i^1}^\top \cdots {y_i^L}^\top)^\top \in \R^{n_i},\\
        b_i &= ({b_i^1}^\top \cdots {b_i^L}^\top)^\top \in \R^r,
    \end{array}
\right.
\]
with $n_i = \sum_{l=1}^L n_i^l$ and $r = \sum_{l=1}^L r_l$ the total number of longitudinal measurements (for subject $i$) and the total dimension of the random effects respectively, as well as the following design matrices
\[ U_i = 
\begin{bmatrix}
  U_{i1} & \cdots & 0\\
  \vdots &  \ddots & \vdots \\
  0 & \cdots & U_{iL}
\end{bmatrix} 
\in \R^{n_i \times q}
\qquad \text{and} \qquad
V_i = 
\begin{bmatrix}
  V_{i1} & \cdots & 0\\
  \vdots &  \ddots & \vdots \\
  0 & \cdots & V_{iL}
\end{bmatrix}
\in \R^{n_i \times r}
\]
with $q = \sum_{l=1}^L q_l$ and where for all $l=1, \ldots, L$, one writes
\[
\left\{
    \begin{array}{ll}
        U_{il} &= \big(u_i^l(t_{i1}^l)^\top \cdots u_i^l(t_{in_i^l}^l)^\top\big)^\top \in \R^{n_i^l \times q_l},\\
        V_{il} &= \big(v_i^l(t_{i1}^l)^\top \cdots v_i^l(t_{in_i^l}^l)^\top\big)^\top \in \R^{n_i^l \times r_l}.
    \end{array}
\right.
\]
From now on, all computations are done conditionally on the design matrices $(U_i)_{i=1, \dots, n}$ and $(V_i)_{i=1, \dots, n}$.
Denoting $(t_1^u, \ldots, t_J^u)$ the $J \in \N_+$ unique failure times, we then extract all representation vectors $\big(\Psi_i(t_j^u)\big)_{j=1,\ldots,J}$ for all subjects $i=1, \dots, n$ before inference and from now on, all computations are also done conditionally on them.
Now, let us make two first hypothesis.
\begin{assumption}
\label{assumption1}
Suppose that the random effects are independent of the latent class membership, and that the latter remain independent conditional on the observed data (namely $T$, $\Delta$ and $Y$).
\end{assumption}
Assumption~\ref{assumption1} states that subject-and-longitudinal outcome specific random effects $b^l$ do not depend on the latent class membership, which is not a strong modeling assumption.
\begin{assumption}
\label{indep-hyp-2}
Suppose that for a given subject $i$ and conditional on the random effects and the latent class membership, all $Y_i^l$ are independent for $l=1, \dots, L$.
\end{assumption}
Assumption~\ref{indep-hyp-2} is similar to standard modeling hypothesis, see for instance~\citet{tsiatis2004joint}.
For all $k = 0, \ldots, K-1$, we denote 
\[ \beta_k = ({\beta_k^1}^\top \cdots {\beta_k^L}^\top)^\top \in \R^q \] 
and 
\[M_{ik} = U_i\beta_k + V_ib_i \in \R^{n_i}. \]

Given~\eqref{eq:link-function} and Assumption~\ref{indep-hyp-2}, each $y_i^l$ is assumed to be from a one-parameter exponential family with respect to a reference measure which is either the Lebesgue measure (e.g., in the Gaussian case) or the counting measure (e.g., in the logistic case).
The conditional distribution of $y_i|b_i, G_i=k$ is then assumed to be from a distribution with a density of the form
\begin{equation}
	\label{eq:exp-family-density}
	f(y_i|b_i, G_i=k) = \exp \big\{(y_i \odot \Phi_i)^\top M_{ik} - c_\phi(M_{ik}) + d_\phi(y_i) \big\},
\end{equation}
with 
\begin{equation}
  \label{eq:def-Phi_i} 
  \Phi_i = (\phi_1^{-1} {\textbf{1}_{n_i^1}}^\top \cdots \phi_L^{-1} {\textbf{1}_{n_i^L}}^\top)^\top \in \R^{n_i}
\end{equation} 
and $\phi = (\phi_1, \ldots, \phi_L)^\top \in \R^L$.
The density described in~\eqref{eq:exp-family-density} encompasses several distributions, see Table~\ref{table:glm}. The functions $c_\phi(\cdot)$ and $d_\phi(\cdot)$ are known as well as the dispersion parameter $\phi_l$, while parameter $\beta_k$ has to be estimated. Note that $d_\phi(\cdot)$ is related to the normalizing constant.
\begin{table}[htb]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{cccccc}
\toprule
 Model & Support & Use cases & $\phi_l$ & $h_l(\cdot)$ in~\eqref{eq:link-function} & $c_\phi(\cdot)$ \\
 \midrule
 Gaussian & $\R$ & Continuous response data & $\sigma_l^2$ & $z \mapsto z$ & $z \mapsto z^2 / 2 \sigma_l^2$ \\ 
 Categorical & $\{0, 1\}^C$ & Outcome with $C$ modalities & 1 & $z \mapsto \log\Big(\dfrac{z}{1 - z} \Big)$ & $z \mapsto \log(1 + e^z)$ \\
 Poisson & $\N$ & Count of occurrences & 1 &  $z \mapsto \log(z)$ & $z \mapsto e^z$ \\
 \bottomrule
\end{tabular}}
\caption[]{Example of standard distributions that fit in the considered setting, given in the univariate case for simplicity of the notations.}
\label{table:glm}
\end{table}

Let us denote 
\[ \theta = \big(\xi_0^\top \cdots \xi_{K-1}^\top, \beta_0^\top \cdots \beta_{K-1}^\top, \phi^\top, \text{vech}(D), \lambda_0^\top, \gamma_0^\top \cdots \gamma_{K-1}^\top\big)^\top \in \R^\vartheta \]
the collection of the $\vartheta \in \N_+$ unknown parameters to estimate. Note that we include $\lambda_0$ in $\theta$. Indeed, we will estimate the baseline using nonparametric maximum likelihood, as a function taking mass at each failure time. So in $\theta$, $\lambda_0$ represents the vector of these baseline hazard quantities, with a dimension equal to $J$.
To write the log-likelihood $\ell_n(\theta)$ (rescaled by $n^{-1}$)  for samples in $\cD_n$ (defined in~\eqref{eq:dataset-def}), corresponding to the joint distribution of the time-to-event and longitudinal outcomes, let us make the following hypothesis.
\begin{assumption}
\label{indep-hyp-3}
Assume that
\begin{equation}
  \label{eq:ind-hyp}
  f_\theta(t_i, \delta_i, y_i | b_i, G_i = k) = f_\theta(t_i, \delta_i| G_i = k) f_\theta(y_i | b_i, G_i = k)
\end{equation}
for all $i=1, \ldots, n$.
\end{assumption}
Assumption~\ref{indep-hyp-3} is a generalization of classical hypothesis used in SREMs and JLCMs~\citep{hickey2016joint}. Remember that the densities are also conditionned by all the representation features $\big(\Psi_i(t_j^u)\big)_{j=1,\ldots,J}$. Hence Assumption~\ref{indep-hyp-3} says that the random effects vector $b_i$, the latent class membership and the representation features account for the association between the longitudinal and event outcomes, which makes sense given Figure~\ref{fig:graphical-model}.
Then, one has
\begin{equation}
	\label{eq:log-lik}
	\ell_n(\theta) = \ell_n(\theta ; \cD_n) = n^{-1} \sum_{i=1}^n \log \sum_{k=0}^{K-1} \pi_{\xi_k}(x_i) f_\theta(t_i, \delta_i| G_i = k) f_\theta(y_i | G_i = k),
\end{equation}
where 
\[f_\theta(t_i, \delta_i| G_i = k) = \big[\lambda(t_i|\cY_i(t_i), G_i = k)\big]^{\delta_i} S_k(t_i) , \]
and
\begin{equation}
  \label{eq:survival-k-def}
  S_k(t_i) = \exp \Big\{-\int_0^{t_i} \lambda(s|\cY_i(s), G_i = k) \dd s \Big\}
\end{equation}
is the survival probability of subject $i$ given that it belongs to latent class $k$.
As expected,~\eqref{eq:log-lik} is a JLCMs like log-likelihood.

\paragraph{Specification of the design matrices.}
 
In many practical applications, subjects show highly nonlinear longitudinal trajectories. We consider a flexible representations for $u^l(t)$ using a high-dimensional vector of time monomials, namely 
\begin{equation}
  \label{eq:alpha-def}
  u^l(t) = (1, t, t^2, \ldots, t^\alpha)^\top
\end{equation}
with $\alpha \in \N_+$.
The idea here is to let the practitioner choose a suitable polynomial order $\alpha$ for the representation -- that could also be tuned automatically using a model selection procedure and AIC~\citep{akaike1974new} for instance.
We then let \[v^l(t) = (1, t)^\top\] so that each trajectory of each subject gets an affine random effect. Hence with this choice in practice, one has $q_l=\alpha + 1$ and $r_l=2$ for all $l=1, \ldots, L$.

\section{Inference}
\label{sec:inference}

In this section, we describe the procedure for estimating the parameters of the lights model. Let us first present the considered penalized objective, then focus on the algorithm proposed for inference, and on its convergence properties.

\subsection{Penalized objective}
\label{sec:penalized-obj}

In order to avoid overfitting and improve the prediction power of our method, we propose to minimize the penalized objective
\begin{equation}
  \label{eq:pen-log-lik}
	\ell_n^\text{pen}(\theta) = - \ell_n(\theta) + \sum_{k=0}^{K-1} \zeta_{1,k} \norm{\xi_k}_{\text{en}, \eta} + \zeta_{2,k} \norm{\gamma_k}_{\text{sg} l_1, \tilde{\eta}}
\end{equation}
where for all $k=0, \ldots, K-1$, we add an elastic net regularization~\citep{zou2005regularization} of the vector $\xi_k$ and a sparse group lasso regularization~\citep{simon2013sparse} of the vector $\gamma_k$, for tuning hyper-parameters $(\zeta_{1,k}, \zeta_{2,k})^\top \in \R_+^2$. Here, for fixed $(\eta, \tilde{\eta}) \in [0, 1]^2$, one has
\[ \norm{z}_{\text{en}, \eta} = (1-\eta)\norm{z}_1 + \dfrac\eta2 \norm{z}_2^2 \]
for the elastic net penalty of any vector $z$, that is a linear combination of the lasso ($\ell_1$) and ridge (squared $\ell_2$) penalties, and
\[ \norm{z}_{\text{sg} l_1, \tilde{\eta}} = (1-\tilde{\eta})\norm{z}_1 + \tilde{\eta} \sum_{l=1}^L\norm{z}_{2,l} \] for the sparse group lasso penalty of any vector $z$, with $\norm{z}_{2,l}=\norm{z^l}_2$, and for which we do not have to account for group sizes since they all have the same one. 
Hence, the resulting optimization problem is written
\begin{equation}
  \label{eq:optim-pb}
   \hat \theta \in \argmin_{\theta \in \R^\vartheta} \ell_n^\text{pen}(\theta).
 \end{equation}

One advantage of the considered regularization strategy is its ability to perform feature selection and pinpoint the most important (time-dependent and time-independent) features relatively to the prediction objective. The support of $\hat \xi_k$ informs on the time-independent features involved in the $k$-th latent class membership. The ridge part allows to handle potential correlation between time-independent features.
On the other hand, for the sparse group lasso penalty, a group $l$ corresponds to a trajectory, that is one longitudinal outcome. So if $\hat \gamma_k^l$ is entirely zeroed (thanks to the group lasso part), it means that the $l$-th longitudinal process is discarded by the model in terms of risk effect for the $k$-th latent class.
Then, the sparse part of the penalty allows to perform representation features selection for each trajectory : for $\hat \gamma_k^l$ that are not entirely zeroed, its support informs on the representation features involved in the $k$-th latent class risk of event for the $l$-th longitudinal outcome.
Note that in practice, the intercept terms are not regularized.

\subsection{A Proximal Quasi-Newton EM}
\label{sec:prox-QNEM}

In order to derive an algorithm for this objective, we introduce a so-called prox-QNEM algorithm, being a combination between an EM algorithm~\citep{dempster1977maximum}, an L-BFGS-B algorithm~\citep{zhu1997algorithm} and a proximal gradient descent algorithm~\citep{beck2009fast}. EM algorithm has already been used for multivariate data joint modeling (see~\citet{lin2002maximum} for instance), but here we face different and original problems: for each subject $i$, the latent variables are the pairs $(G_i, b_i)$ (not only the random effects); and then, we want to minimize the penalized objective $\ell_n^\text{pen}$ (not ``only'' the negative log-likelihood).

We first need to compute the negative completed log-likelihood (here scaled by $n^{-1}$), namely the negative joint distribution of $\cD_n$, $\textbf{\textit{b}} = (b_1, \ldots, b_n)$ and $\textbf{\textit{G}} = (G_1, \ldots, G_n)$.
It can be written
\begin{align*}
  \ell_n^\text{comp}(\theta) &= \ell_n^\text{comp}(\theta ; \cD_n, \textbf{\textit{b}}, \textbf{\textit{G}}) \\ 
  &= - n^{-1} \sum_{i=1}^n -\dfrac12 (r \log 2\pi + \log|D| + b_i^\top D^{-1}b_i) + \sum_{k=0}^{K-1} \ind{\{G_i=k\}} \Big[ \log \pi_{\xi_k}(x_i) \\ 
  & \quad + \delta_i \Big(\log \lambda_0(t_i) + \gamma_k^\top \Psi_i(t_i) \Big) - \int_0^{t_i} \lambda_0(s) \exp \big\{ \gamma_k^\top \Psi_i(s) \big\} \dd s \\
  & \quad + (y_i \odot \Phi_i)^\top M_{ik} - c_\phi(M_{ik}) + d_\phi(y_i) \Big].
\end{align*}
Suppose that we are at step $w + 1$ of the algorithm, with current iterate denoted $\theta^{(w)}$. 

\paragraph*{E-step.}

We need to compute the expected negative log-likelihood of the complete data conditional on the observed data and the current estimate of the parameters given by 
\begin{equation}
  \label{eq:Q-def}
  \cQ_n(\theta, \theta^{(w)}) = \E_{\theta^{(w)}}[\ell_n^\text{comp}(\theta) | \cD_n].
\end{equation}
Given Assumption~\ref{assumption1}, the previous expression requires to compute expectations of the form
\[ \E_{\theta^{(w)}}[ g(b_i, G_i) | t_i, \delta_i, y_i] = \sum_{k=0}^{K-1} \pi_{ik}^{\theta^{(w)}} \int_{\R^r} g(b_i, G_i) f(b_i | t_i, \delta_i, y_i ; \theta^{(w)}) \dd b_i \]
for different functions $g$, where we denote 
\begin{equation}
  \label{eq:pi_ik-def}
  \pi_{ik}^{\theta^{(w)}} = \P_{\theta^{(w)}}[G_i = k | t_i, \delta_i, y_i] 
\end{equation}
the posterior probability of the latent class membership using parameters $\theta^{(w)}$. 
Then, either $g(b_i, G_i) = \tilde g(b_i)$ (either $\tilde g_1: b_i \mapsto b_i$ or $\tilde g_2: b_i \mapsto b_i b_i^\top$), or $g(b_i, G_i) = g_k(G_i)$ with $g_k~:~G_i \mapsto \ind{\{G_i=k\}}$.

In the case $g(b_i, G_i) = \tilde g(b_i)$, one has
\begin{equation*}
  \E_{\theta^{(w)}}[ \tilde g(b_i) | t_i, \delta_i, y_i] = \int_{\R^r} \tilde g(b_i) f_{\theta^{(w)}}(b_i | t_i, \delta_i, y_i) \dd b_i = \dfrac{ \sum_{k=0}^{K-1} \pi_{\xi_k^{(w)}}(x_i) \Lambda_{ik,\tilde g}^{\theta^{(w)}}}{\sum_{k=0}^{K-1} \pi_{\xi_k^{(w)}}(x_i) \Lambda_{ik,1}^{\theta^{(w)}}}
\end{equation*}
where
\begin{equation}
  \label{eq:Lambda_ik-b_i}
  \Lambda_{ik,\tilde g}^{\theta^{(w)}} =  f_{\theta^{(w)}}(t_i, \delta_i | G_i = k) f_{\theta^{(w)}}(y_i | G_i = k) \int_{\R^r} \tilde g(b_i) f_{\theta^{(w)}}(b_i | y_i, G_i = k) \dd b_i,
\end{equation}
and in the Gaussian case used in practice one has
\begin{align*}
  y_i | G_i = k ; \theta^{(w)} &\sim \cN\big(U_i\beta_k^{(w)}, V_iD^{(w)}V_i^\top + \Sigma_i^{(w)}\big), \\
  b_i | y_i, G_i=k ; \theta^{(w)} &\sim \cN \big(O_{i,k}^{(w)}, W_i^{(w)}\big),  
\end{align*}
with $O_{i,k}^{(w)}=W_i^{(w)}V_i^T{\Sigma_i^{(w)}}^{-1}(y_i - U_i\beta_k^{(w)})$ and $W_i^{(w)} = (V_i^\top{\Sigma_i^{(w)}}^{-1}V_i + {D^{(w)}}^{-1})^{-1}$. Hence, what is interesting here is that~\eqref{eq:Lambda_ik-b_i} is actually closed-formed since 
\[ \E_{\theta^{(w)}}[ \tilde g_1(b_i) | y_i, G_i = k] = O_{i,k}^{(w)} \quad \text{and} \quad \E_{\theta^{(w)}}[ \tilde g_2(b_i) | y_i, G_i = k] = W_i^{(w)} + O_{i,k}^{(w)}{O_{i,k}^{(w)}}^\top\]
and then tractable analytically. Whereas in classical SREMs, some form of approximation must be used in practice to compute this quantity, like numerical integration techniques (for instance Gaussian quadrature) or Monte Carlo approximation.

Now in the case $g = g_k$, one has
\begin{equation}
\label{eq:pi_ik-def}
  \E_{\theta^{(w)}}[g_k(Gi) | t_i, \delta_i, y_i] = \pi_{ik}^{\theta^{(w)}} = \dfrac{\pi_{\xi_k^{(w)}}(x_i) \Lambda_{ik,1}^{\theta^{(w)}}}{\sum_{k=0}^{K-1} \pi_{\xi_k^{(w)}}(x_i) \Lambda_{ik,1}^{\theta^{(w)}}}.
\end{equation}

\paragraph*{Proximal Quasi-Newton M-step.}
Let us denote
\begin{equation}
  \label{eq:M-step-obj}
  \cQ_n^\text{pen}(\theta, \theta^{(w)}) = \cQ_n(\theta, \theta^{(w)}) + \sum_{k=0}^{K-1} \zeta_{1,k} \norm{\xi_k}_{\text{en}, \eta} + \zeta_{2,k} \norm{\gamma_k}_{\text{sg} l_1, \tilde{\eta}}.
\end{equation}
Here, we need to compute 
\[\theta^{(w+1)} \in \argmin_{\theta \in \R^\vartheta} \cQ_n^\text{pen}(\theta, \theta^{(w)}).\]
We then present the parameters updates in the order given in Algorithm~\ref{alg:prox-QNEM}.
First, the update of $D^{(w)}$ is naturally given in closed-form by
\begin{equation}
  \label{eq:update_D}
  D^{(w+1)} = n^{-1} \sum_{i=1}^n \E_{\theta^{(w)}}[ b_i b_i^\top | t_i, \delta_i, y_i].
\end{equation}
Then, let us focus on the update of $\xi_k^{(w)}$ for $k=0, \ldots, K-1$. We denote
\[ P^{(w)}_{n, k}(\xi_k) = -n^{-1} \sum_{i=1}^n \sum_{k=0}^{K-1} \pi_{ik}^{\theta^{(w)}} \log \pi_{\xi_k}(x_i) \]
based on the quantities involved in $\cQ_n(\theta, \theta^{(w)})$ that depend on $\xi_k$. The update for $\xi_k^{(w)}$ therefore requires to solve the following convex minimization problem
\begin{equation}
  \label{eq:minimization-xi_k}
  \xi_k^{(w+1)} \in \argmin_{\xi_k \in \R^p} P^{(w)}_{n,k}(\xi_k) + \zeta_{1,k} \norm{\xi_k}_{\text{en}, \eta}.
\end{equation}
It looks like the logistic regression objective, where labels are not fixed but softly encoded by the expectation step (computation of $\pi_{ik}^{\theta^{(w)}}$ in~\eqref{eq:pi_ik-def}). We then choose to solve~\eqref{eq:minimization-xi_k} using the L-BFGS-B algorithm~\citep{zhu1997algorithm} which belongs to the class of quasi-Newton optimization routines and solves the given minimization problem by computing approximations
of the inverse Hessian matrix of the objective function. It can deal with differentiable convex objectives with box constraints.
In order to use it with $\ell_1$ penalization, which is not differentiable, we use the trick borrowed from \citet{andrew2007scalable}: for $a \in \R$, write $|a| = a^+ + a^-$, where $a^+$ and $a^-$ are respectively the positive and negative part of $a$, and add the constraints $a^+ \geq 0$ and $a^- \geq 0$.
Namely, we rewrite the minimization problem~\eqref{eq:minimization-xi_k} as the following differentiable problem with box constraints
\begin{equation}
  \label{eq:sub-problem-xi_k}
  \begin{split}
    \text{minimize}& \quad \quad P_{n, k}^{(w)}(\xi_k^+ - \xi_k^-) + \zeta_{1,k} \big((1 - \eta) \sum_{j=1}^p (\xi_{k,j}^+ + \xi_{k,j}^-) + \dfrac \eta 2 \norm{{\xi_k}^+ - {\xi_k}^-}_2^2 \big) \\
    \text{subject to}& \quad \quad \xi_{k,j}^+ \geq 0 \text{ and } \xi_{k,j}^- \geq 0 \text{ for } j = 1, \ldots, p
  \end{split} 
\end{equation}
where $\xi_k^\pm = (\xi_{k,1}^\pm, \ldots, \xi_{k,p}^\pm)^\top$. The L-BFGS-B solver requires the exact value of the gradient, which is easily given by
\begin{equation}
  \label{eq:grad-xi_k}
  \frac{\partial P_{n,k}^{(w)}(\xi_k)}{\partial \xi_k} = -n^{-1} \sum_{i=1}^n  \big(\pi_{ik}^{\theta^{(w)}} - \pi_{\xi_k}(x_i) \big) x_i.
\end{equation}
In practice, we use the \texttt{Python} solver \texttt{fmin\_l\_bfgs\_b} from \texttt{scipy.optimize}~\citep{virtanen2020scipy}. Note that for computational reasons, it is not clever to use a too small solver tolerance in the early steps of the overall algorithm, where we call tolerance the value for which iterations stop when the stopping criterion is below it. To speed up the overall algorithm, we then decrease the L-BFGS-B tolerance with the iterations $w$.

Concerning the update of $\beta_k^{(w)}$ for $k=0, \ldots, K-1$, let us follow the same strategy by denoting
\begin{equation*}
  R^{(w)}_{n,k}(\beta_k) = -n^{-1} \sum_{i=1}^n \pi_{ik}^{\theta^{(w)}} \Big[ (y_i \odot \Phi_i^{(w)})^\top \E_{\theta^{(w)}}[ M_{ik} | t_i, \delta_i, y_i] - \E_{\theta^{(w)}}[ c_{\phi^{(w)}}(M_{ik}) | t_i, \delta_i, y_i] \Big]
\end{equation*}
based on the quantities involved in $\cQ_n(\theta, \theta^{(w)})$ depending on $\beta_k$. The update for $\beta_k^{(w)}$ therefore requires to solve the following convex minimization problem
\begin{equation}
  \label{eq:minimization-beta_k}
  \beta_k^{(w+1)} \in \argmin_{\beta_k \in \R^q} R^{(w)}_{n,k}(\beta_k).
\end{equation}
The gradient of $R_{n,k}^{(w)}$ for the Gaussian case is here given by
\begin{equation}
  \label{eq:grad-beta_k}
  \frac{\partial R_{n,k}^{(w)}(\beta_k)}{\partial \beta_k} = -n^{-1} \sum_{i=1}^n \pi_{ik}^{\theta^{(w)}} \Big[ U_{i}^\top \Sigma_i^{(w)} I_{n_{i}} \big(y_i - U_{i}\beta_k - V_{i} \E_{\theta^{(w)}}[ b_i | t_i, \delta_i, y_i]\big)\Big].
\end{equation}
The closed-form update is then given by

\begin{equation}
  \label{eq:update_beta}
  {\beta_k}^{(w+1)}= \dfrac{\sum_{i=1}^n \pi_{ik}^{\theta^{(w)}} \Big[U_i^\top I_{n_i} (y_i - V_i \E_{\theta^{(w)}}[ b_i | t_i, \delta_i, y_i])\Big]}{\sum_{i=1}^n \pi_{ik}^{\theta^{(w)}} U_i^\top I_{n_i} U_i}.
\end{equation}
Now, for the update of $\gamma_k^{(w)}$ for $k=0, \ldots, K-1$, we similarly denote
\[Q^{(w)}_{n,k}(\gamma_k) = -n^{-1} \sum_{i=1}^n \pi_{ik}^{\theta^{(w)}} \Big[\delta_i \gamma_k^\top \Psi_i(t_i) - \sum_{j=1}^J \lambda_0^{(w)}(t_j^u) \exp \big\{\gamma_k^\top \Psi_i(t_j^u)\big\} \ind{\{t_j^u \leq t_i\}} \Big]\]
based on the quantities involved in $\cQ_n(\theta, \theta^{(w)})$ that depend on $\gamma_k$. The integration over the survival process has been replaced with a finite sum over the process evaluated at the $J$, since $\lambda_0^{(w)}$ defined in~\eqref{eq:update_lambda_0} is always zero except at observed event times. The update for $\gamma_k^{(w)}$ requires to solve the following convex minimization problem
\begin{equation}
  \label{eq:minimization-gamma_k}
  \gamma_k^{(w+1)} \in \argmin_{\gamma_k \in \R^{L\cA}} Q^{(w)}_{n,k}(\gamma_k) + \zeta_{2,k} \norm{\gamma_k}_{\text{sg} l_1, \tilde{\eta}}.
\end{equation}

The previous trick we used to handle the non-differentiability of the $\ell_1$ part in the elastic net is no longer sufficient for~\eqref{eq:minimization-gamma_k}, since the $\ell_2$ norm in the sparse group lasso is not squared, leading to a non-differentiability at 0 (which is precisely the criterion exploited by the penalty to set some groups of coefficients to exactly 0~\citep{simon2013sparse}). Then, we choose to solve problem~\eqref{eq:minimization-gamma_k} using the proximal gradient descent~\citep{boyd2004convex} described in Algorithm~\ref{alg:ISTA}, where we first define
\[p_{\varrho}(y) = \argmin_u \Big\{\dfrac{1}{2\varrho} \left\lVert u - \big(y - \varrho  \nabla f(y) \big)\right\rVert_2^2 + \zeta \norm{u}_{\text{sg} l_1, \tilde{\eta}} \Big\}.\]

\vspace{.5cm}

\begin{algorithm}[H]
\DontPrintSemicolon
\caption{Proximal gradient descent ISTA$_{\text{sg} l_1}$($v$, $f$, $\tilde \eta$, $\zeta$)}
\label{alg:ISTA}
\KwInput{A vector $v$, a function $f$ (its gradient $\nabla f$), hyper-parameters $\tilde \eta$, $tol$ and $\zeta$}
\KwOutput{$\flat^{\breve{w}^{max}}$}
Initialize $\flat^{(0)}=v$, $\varrho^0 > 0$, some $\epsilon > 1$ \\
\For{$\breve{w} = 0,\ldots,$ until convergence}    
{Backtracking line search : find the smallest nonnegative integer $i^{\breve{w}}$ such that
$f\big(p_{\tilde{\varrho}_{\breve{w}}}(\flat^{(\breve{w})})\big) \leq f(\flat^{(\breve{w})}) + \big<\big(p_{\tilde{\varrho}_{\breve{w}}}(\flat^{(\breve{w})}) - \flat^{(\breve{w})}\big), \nabla f(\flat^{(\breve{w})})\big> + \dfrac{1}{2\tilde{\varrho}_{\breve{w}}}\norm{p_{\tilde{\varrho}_{\breve{w}}}(\flat^{(\breve{w})}) - \flat^{(\breve{w})}}_2^2$ 
with $\tilde{\varrho}_{\breve{w}} = \epsilon^{i^{\breve{w}}}\varrho^{\breve{w}}$\\
Set $\varrho^{(\breve{w} + 1)} = \tilde{\varrho}_{\breve{w}}$ \\
$\flat^{(\breve{w}+1)} = p_{\varrho^{(\breve{w} + 1)}}(\flat^{(\breve{w})}) \coloneqq\text{prox}_{\text{sg} l_1, \tilde{\eta}, \zeta} \big(\flat^{(\breve{w})} - \varrho^{(\breve{w} + 1)} \nabla f(\flat^{(\breve{w})}) \big)$ \\
\If{$\dfrac{\norm{\flat^{(\breve{w}+1)} - \flat^{(\breve{w})}}_2}{\varrho^{(\breve{w} + 1)}} < tol$}
  {
    \textbf{Return:} {$\flat^{\breve{w}}$}
  }
}
\end{algorithm}

\vspace{.5cm}
Lemma~\ref{lemma:prox-sgl1} bellow states that one can easily compute the proximal operator of the sparse group lasso defined in Algorithm~\ref{alg:ISTA}.
\begin{lemma}
\label{lemma:prox-sgl1}
The proximal operator of the sparse group lasso can be expressed as the composition of the group lasso and the lasso proximal operators, that is
\normalfont
\begin{equation*}
  \text{prox}_{\text{sg} l_1,\tilde \eta, \zeta} = \text{prox}_{\zeta \tilde \eta \sum_{l=1}^L \norm{\cdot}_{2,l}} \circ \text{prox}_{\zeta (1 - \tilde \eta) \norm{\cdot}_1}.
\end{equation*}
\end{lemma}
The two proximal operators on the right hand side of Lemma~\ref{lemma:prox-sgl1} are both well known analytically~\citep{bach2011optimization} and tractable. We used the \texttt{Python} library \texttt{copt} for the implementation of proximal gradient descent~\citep{copt} and we propose in our \texttt{lights} package a first \texttt{Python} implementation for the proximal operator of the sparse group lasso based on Lemma~\ref{lemma:prox-sgl1}.
A proof of Lemma~\ref{lemma:prox-sgl1} is proposed in Appendix~\ref{sec:proof-lemma-prox-sgl1}.
Hence, we update $\gamma_k^{(w)}$ with the following step
\begin{equation}
  \label{eq:gamma-update}
  \gamma_k^{(w+1)} = \text{ISTA}_{\text{sg} l_1}\big(\gamma_k^{(w)}, Q^{(w)}_{n,k}(\cdot), \tilde \eta, \zeta_{2,k}\big)
\end{equation}
Note that the warmstart initialization is left to the user's choice, as well as the ISTA acceleration~\citep{beck2009fast}, since warmstart can diminish acceleration effectiveness~\citep{tibshirani2010proximal}. The gradient of $Q_{n,k}^{(w)}$ is here given by
\begin{align}
  \label{eq:grad-Q}
  &\frac{\partial Q_{n,k}^{(w)}(\gamma_k)}{\partial \gamma_{k,a}^l} = -n^{-1} \sum_{i=1}^n \pi_{ik}^{\theta^{(w)}} \Psi_{i, a}^l(t_i) \Big[ \delta_i - \sum_{j=1}^J \lambda_0^{(w)}(t_j^u) \exp \big\{\gamma_k^\top \Psi_i(t_j^u) \big\} \ind{\{t_j^u \leq t_i\}} \Big]
\end{align}
for all $a = 1, \ldots, \mathcal{A}$ and $l = 1, \ldots, L$.

For the update of $\lambda_0^{(w)}$, we treat the jump size at each uncensored observed event times as parameters to be estimated~\citep{klein1992semiparametric}, and the closed-form update obtained by cancelling the gradient is given by
\begin{equation}
  \label{eq:update_lambda_0}
  \lambda_0^{(w+1)}(t)= \dfrac{\sum_{i=1}^n \delta_i \ind{\{t=t_i\}}}{\sum_{i=1}^n \sum_{k=0}^{K-1} \pi_{ik}^{\theta^{(w)}} \exp \big\{{\gamma_k^{(w+1)}}^\top \Psi_i(t)\big\} \ind{\{t_i \geq t\}} },
\end{equation}
for all $t \geq 0$, which is a Breslow like estimator~\citep{breslow1972contribution} adapted to our model. 

Finally, for the update of $\phi^{(w)}$ and regarding Table~\ref{table:glm}, we focus on the Gaussian case being particularly useful in practice. It is obtained in closed-form by
\begin{align}
  \label{eq:update_phi}
  \phi_l^{(w+1)} = \big(\sum_{i=1}^n n_i^l \big)^{-1} &\sum_{i=1}^n \sum_{k=0}^{K-1} \pi_{ik}^{\theta^{(w)}} \Big[ \big(y_i^l - U_{il} {\beta_k^l}^{(w+1)}\big)^\top \Big(y_i^l - U_{il} {\beta_k^l}^{(w+1)} \nonumber \\
  & - 2V_{il} \E_{\theta^{(w)}}[ b_i^l | t_i, \delta_i, y_i]\Big) + \Tr\big(V_{il}^\top V_{il} \E_{\theta^{(w)}}[ b_i^l {b_i^l}^\top | t_i, \delta_i, y_i]\big) \Big].
\end{align}
Appendix~\ref{sec:prox-QNEM class} gives some details about the way we implement the equations and their computation in practice.

\paragraph*{Initialization.}
Our algorithm gives a local minimum, and it is clever to choose an initial value $\theta^{(0)}$ close to the final solution $\hat \theta$, so that the number of iterations required to reach convergence is reduced. We then give some details about the starting point $\theta^{(0)}$ of Algorithm~\ref{alg:prox-QNEM}.
For all $k = 0, \ldots, K-1$, we first choose $\xi_k^{(0)} = \mathbf{0}_d$ and ${\gamma_k}^{(0)} = \mathbf{0}_{L\cA}$. Then, we initialize $\lambda_0^{(0)}$ like if there is no latent classes ($\gamma_{0}^{(0)} = \cdots = \gamma_{K-1}^{(0)}$) with a standard Cox proportional hazards regression with time-independent features using the \texttt{Python} library \texttt{tick}. Finally, the longitudinal submodels parameters $\beta_k^{(0)}$, $D^{(0)}$ and $\phi^{(0)}$ are initialized -- again like if there is no latent classes ($\beta_0^{(0)} = \cdots = \beta_{K-1}^{(0)}$) -- using a multivariate linear mixed model with an explicit EM algorithm (details on the algorithm are given in Appendix~\ref{sec:MLMM}, and details on the implementation in Appendix~\ref{sec:MLMM class}), being itself initialized with univariates fits using the \texttt{Python} package \texttt{statsmodels}.

\paragraph*{The prox-QNEM algorithm.}
Algorithm~\ref{alg:prox-QNEM} describes the main steps of the resulting prox-QNEM algorithm to solve the optimization problem~\eqref{eq:optim-pb}. 
\begin{algorithm}[!htb]
\DontPrintSemicolon
\caption{prox-QNEM algorithm for the lights model inference}
\label{alg:prox-QNEM}
\KwInput{Training data $\cD_n$~\eqref{eq:dataset-def}; tuning hyper-parameters $(\zeta_{1,k}, \zeta_{2,k})_{k=0,\ldots,K-1}$}
\KwOutput{Last parameters $\hat \theta \in \R^\vartheta$}
\tcc{Initialization}
Compute the starting parameters $\theta^{(0)} \in \R^\vartheta$ \\
\For{$w = 1,\ldots,$ until convergence}  
{ 
  \tcc{E-step}
  Compute $\Lambda_{ik,\tilde g}^{\theta^{(w)}}$ using~\eqref{eq:Lambda_ik-b_i} for $\tilde g_1$ and $\tilde g_2$\\
  Compute $\pi_{ik}^{\theta^{(w)}}$ using~\eqref{eq:pi_ik-def}\\
  \tcc{Proximal Quasi-Newton M-step}
  Update $D^{(w+1)}$ using~\eqref{eq:update_D}\\
  Update $(\xi_k^{(w+1)})_{k=0,\ldots,K-1}$ by solving~\eqref{eq:sub-problem-xi_k} \\
  Update $(\beta_k^{(w+1)})_{k=0,\ldots,K-1}$ by solving~\eqref{eq:update_beta} \\
  Update $(\gamma_k^{(w+1)})_{k=0,\ldots,K-1}$ by solving~\eqref{eq:gamma-update} \\
  Update $\lambda_0^{(w+1)}$ using~\eqref{eq:update_lambda_0}\\
  Update $\phi^{(w+1)}$ using~\eqref{eq:update_phi} \\
}
\textbf{Return:} {$\hat \theta$}
\end{algorithm}

Then in practice, the convergence for Algorithm~\ref{alg:prox-QNEM} is declared when the relative objective $\big(\ell_n^\text{pen}(\theta^{(w+1)}) - \ell_n^\text{pen}(\hat\theta^{(w)}) \big) / \ell_n^\text{pen}(\hat\theta^{(w)})$ goes below a chosen threshold.

\subsection{Convergence to a stationary point}

Let us address here convergence properties of the prox-QNEM algorithm described in the previous section. Since in~\eqref{eq:M-step-obj} we only minimize $\cQ_n^\text{pen}(\theta, \theta^{(w)})$ and not directly $\cQ_n(\theta, \theta^{(w)})$ defined in~\eqref{eq:Q-def} as in a classical EM~\citep{wu1983convergence}, we are in a generalized EM (GEM) setting~\citep{dempster1977maximum}. For such algorithm, one has the descent property saying that the objective function~\eqref{eq:pen-log-lik} decreases at each iteration, namely 
\[\ell^{\text{pen}}_n(\theta^{(w+1)}) \leq \ell^{\text{pen}}_n(\theta^{(w)}),\]
which can be observed in Figure ?.
Now, let us make a classical hypothesis.
\begin{assumption}
  \label{hyp:bounded}
  Suppose that $\ell^{\text{pen}}_n$ is bounded for all $\theta$.
\end{assumption}
Assumption~\ref{hyp:bounded} implies that $w \mapsto \ell^{\text{pen}}_n(\theta^{(w)})$ decreases monotically to a finite limit. Then, one has the following convexity property with the Gaussian case used in practice.
\begin{lemma}
\label{lem:strictly-convex}
$\cQ_n^{\text{pen}}(\theta, \theta^{(w)})$ is continuous in $\theta$ and $\theta^{(w)}$, and for any fixed $\theta^{(w)}$, it is a convex function in $\theta$, and strictly convex in each coordinate of $\theta$.
\end{lemma}
Hence, one can state the following theorem about the convergence of the prox-QNEM algorithm to a stationary point, being here a local minimum.
\begin{theorem}
\label{th:cvg}
Under Assumption~\ref{hyp:bounded}, every cluster point $\bar{\theta}$ of the sequence $\{ \theta^{(w)}\}_{w \geq 1}$ generated by the prox-QNEM algorithm is a stationary point of the objective function~\eqref{eq:pen-log-lik}, that is
\[\forall \varepsilon > 0, V_\varepsilon(\bar{\theta}) \cap \{ \theta^{(w)}\}_{w \geq 1} \setminus \{\bar{\theta}\} \neq \varnothing \implies \forall \tilde \theta \in \R^\vartheta, \underset{u \rightarrow 0}{\lim} \frac{\ell^{\text{pen}}_n(\bar{\theta} + \tilde \theta u) - \ell^{\text{pen}}_n(\bar{\theta})}{u} \geq 0 ,\]
with $V_\varepsilon(\bar{\theta})$ the epsilon-neighbourhood of $\bar{\theta}$.
\end{theorem}
The proof of Lemma~\ref{lem:strictly-convex} is straightforward, and we follow the proof of Theorem 1 in~\citet{bussy2019c} to prove Theorem~\ref{th:cvg}.

\subsection{The case $K=2$}
\label{sec:K=2}

In many practical applications -- including those addressed in Section~\ref{sec:application} -- we are interested in identifying one latent class of the population with a high risk of adverse event compared to the others. Then, in the following, we consider $G \in \{ 0, 1\}$ where $G=1$ means high-risk of early adverse event and $G=0$ means low risk.
To simplify notations, let us set $\xi = \xi_1$, $\pi_\xi(x)$ the conditional probability that a subject belongs to the latent class with high risk of adverse event given its time-independent features $x$, and $\zeta_1 = \zeta_{1,1}$.
In this context, which is the one we consider in practice in Sections~\ref{sec:simulation study} and~\ref{sec:application}, we suppose that the ``right'' penalty strength for $\gamma_k$ does not depend on $k$, so that we denote $\zeta_2 = \zeta_{2,0} = \zeta_{2,1}$. 

\paragraph{Cross-validation procedure.}

The hyper-parameters $(\zeta_1, \zeta_2)^\top \in \R_+^2$ are then tuned using a Bayesian optimization method~\citep{snoek2012practical}, with the C-index score and the predictive marker both defined in Section~\ref{sec:evaluation strategy}. In practice, we use the \texttt{Python} package \texttt{hyperopt}~\citep{bergstra2013hyperopt} and the Tree-structured Parzen Estimator~\citep{bergstra2011algorithms}, which is a sequential model-based optimization (SMBO) approach. SMBO methods sequentially construct models to approximate the performance of hyperparameters based on historical measurements, and then subsequently choose new hyperparameters to test based on this model.
Moreover, the search interval for hyper-parameter $\zeta_1$ is automatically computed in a data driven way described in Appendix~\ref{sec:auto-grid-cv}, while the search intervals for $\zeta_2$ is determined empirically.
% TODO: Figure de visualisation de la CV de (\zeta_1, \zeta_2) en 3D


\section{Performance evaluation}
\label{sec:Performance evaluation}

In this section, we first present the proposed evaluation strategy to assess real-time prognostic prediction performances. We then introduce the considered models for performance comparisons.

\subsection{Evaluation strategy}
\label{sec:evaluation strategy}

When validating predictions or comparing performances of competing models in a survival context, one can be interested either in the discriminative power of the predictive rule and use concordance measures such as the C-index~\citep{heagerty2005survival} (defined in Section~\ref{sec:evaluation strategy}), or in the predictive accuracy of the rule~\citep{schemper2000predictive}.
Developments in the field of joint modeling have primarily focused on modeling and estimation, and most studies do not consider goodness-of-fit nor generalization power in a prognostic prediction perspective~\citep{hickey2016joint}. However, with the prospect of using prognostic prediction in real-time on a daily basis, practitioners will naturally require predictive prognostic tools to evaluate models fit and compare models in terms of discriminative power. So we choose to put ourselves in what we call a ``real-time prediction paradigm''. 

\paragraph{Real-time prediction paradigm.}

Once the learning phase is achieved for the model on a training set (so that one obtains $\hat\theta$ from~\eqref{eq:optim-pb} using our prox-QNEM algorithm introduced in Section~\ref{sec:prox-QNEM}), we want to assess real-time risk prediction performances on a test set.
Denoting $t^{max}_i$ the time for subject $i$ in the test set when one wants to perform the risk prediction -- so in practice, the time up to which one has data measurements for $Y_i$, say the ``present'' time for prediction -- one wants then to predict a prognostic marker for subject $i$ using all data available up to $t^{max}_i$, but without using the supervision labels $(t_i, \delta_i)$.

\paragraph{Predictive marker.}

The question is now to choose a discriminative marker rule for risk prediction to be used in the cross-validation procedure for selecting the best regularization hyper-parameters, and of course to be used as final risk prediction after hyper-parameters fine-tuning.
Posterior risk classification for subject $i$ and latent class $k$ can be made through $\pi_{ik}^{\hat\theta}$ (see~\eqref{eq:pi_ik-def}), and such posterior probabilities have been considered for goodness-of-fit evaluation in other JLCMs models, see~\citet{proust2014joint} for instance.

But in the real-time prediction paradigm, it makes no sense from a practical point of view to use this marker rule as is, since the latter requires to know the survival labels $(t_i, \delta_i)$, being intrinsically unknow in the paradigm. A natural and appropriate marker rule of the lights model for subject $i$ being in latent class $k$ in our context would rather be 
\begin{equation}
  \label{eq:marker-def}
  \hat \cR_{ik} = \P_{\hat \theta}[G_i=k | T^\star_i > t^{max}_i, y_i] = \dfrac{\pi_{\hat \xi_k}(x_i) S_k(t^{max}_i) f_{\hat \theta}(y_i | G_i=k)}{\sum_{k=0}^{K-1} \pi_{\hat \xi_k}(x_i) S_k(t^{max}_i) f_{\hat \theta}(y_i | G_i=k)},
\end{equation}
where $S_k$ is defined in~\eqref{eq:survival-k-def}.
Note that marker~\eqref{eq:marker-def} is obtained from $\pi_{ik}^{\hat\theta}$ in~\eqref{eq:pi_ik-def} taking $(t_i, \delta_i) = (t^{max}_i, 0)$. Let us recall that in practice, one considers the case $K=2$ for the lights, see Section~\ref{sec:K=2}.

\paragraph{The C-index metric}

We detail in this section the chosen metric to evaluate risk prediction performances. 
Let us denote by $\hat \cR_i$ the predictive marker for a subject $i$ at $t^{max}_i$ and from a given model (for the lights, $\hat \cR_i = \hat \cR_{ik}$ in~\eqref{eq:marker-def} with $k=1$).
A common concordance measure that does not depend on time is the C-index~\citep{harrell1996tutorial} defined by
\begin{equation*}
  \cC =\P[\hat \cR_i > \hat \cR_j | T^\star_i < T^\star_j],
\end{equation*}
with $i \neq j$ two independent subjects (which does not depend on $i, j$ under the i.i.d. sample hypothesis). 
In our case,  $T^\star$ is subject to right censoring, so one would typically consider the modified $\cC_\tau$ defined by
\begin{equation*}
  \cC_\tau =\P[\hat \cR_i > \hat \cR_j | T_i < T_j , T_i < \tau],
\end{equation*}
with $\tau$ corresponding to the fixed and prespecified follow-up period duration \citep{heagerty2005survival}. A Kaplan-Meier estimator for the censoring distribution leads to a nonparametric and consistent estimator of $\cC_\tau$ \citep{uno2011c}, already implemented in the \texttt{Python} package \texttt{lifelines}.
Hence in the following, we consider the C-index metric to assess performances.

Note that other metrics have been proposed to compare individual risk predictions. In~\citet{blanche2015quantifying} for instance, authors use dynamic prediction accuracy curves (of AUC or Brier score) with the idea of moving what is called the ``landmark time'', that is the time at which predictions are made and on which the amount of available information depends, corresponding to our $t^{max}_i$. But comparing curves in an automatic way (in a cross-validation process for instance) is complicated, and the comparisons proposed in the aforementioned paper require \textit{a priori} choices of time window thresholds (in particular to get back to binary predictions, being always questionable in survival analysis~-v\citep{bussy2019comparison}), which is not the case of the C-index metric.
Finally, the question of the choice of $t^{max}_i$ in a study to assess a model performances, or to compare models, is discussed in the following paragraph. It can be sensed that the closer $t^{max}_i$ gets to $T^\star_i$, the easier it will be for a model to make good predictions.

\paragraph{Procedure.}
Let us describe now in Algorithm~\ref{alg:evaluation} the procedure we follow to evaluate model performances on simulated data in Section~\ref{sec:simulation study} and on real data in Section~\ref{sec:application}. Here we do not give details on the cross-validation step, but it follows the same idea : for each fold, we sample the $t_i^{max}$ and truncate $y_i$ for $i$ in the test set of the fold.
\begin{algorithm}[!htb]
\DontPrintSemicolon
\caption{Procedure followed to assess performances of a given model in our real-time prediction paradigm.}
\label{alg:evaluation}
\KwInput{Dataset $\cD_n$~\eqref{eq:dataset-def} \textbf{only if} \textit{\texttt{simulation = false}} ; a \texttt{model} under study}
\KwOutput{Confidence intervals on C-index metric as well as on running time.}
\tcc{We run $\breve{R}=100$ independant experiments}
$seed_0 = 0$ \\
\For{$\breve{r} = 1,\ldots,\breve{R}$}
{
  $\texttt{start\_time} = \texttt{time}()$ \\
  $seed_{\breve{r}} = seed_{\breve{r}-1} + 1$ \\
  \If{\texttt{simulation = true}}
  {
    {$\cD_n \leftarrow \texttt{simulate}(seed_{\breve{r}})$ \tcc{Sample a new dataset at each round $\breve{r}$}}
  }
  $(\cD_{n_{train}}, \cD_{n_{test}}) \leftarrow \texttt{split\_train\_test}(\cD_n, seed_{\breve{r}})$ \\
  $\texttt{model.cross\_validate}(\cD_{n_{train}})$ \tcc{Select the best hyper parameters}
  \texttt{model.fit}$(\cD_{n_{train}})$ \tcc{Learn $\hat \theta$}
  \For{$i = 1,\ldots,n_{test}$}
  {
    $t_i^{max} \sim t_i \times \big(1 - \text{Beta}(2, 5)\big)$ \tcc{See Figure~\ref{fig:timax-pdf}}
    $y_i \leftarrow \big(Y_i^l(t_{ij}^l) \big)_{\substack{j=1, \ldots, n_i^l-1 \\ l=1, \ldots, L \ \ \ }} \text{ with } t_{ij}^l \leq t_i^{max}$ \tcc{Truncate $y_i$, see~\eqref{eq:def-yil}}
    $\mathcal{X}_i = (x_i, y_i)$ \\
    \If{\normalfont \texttt{model = lights}}
    {
      $\big(\Psi_i(t_j^u)\big)_{j=1,\ldots,J} \leftarrow \texttt{extract\_features}(y_i)$ \tcc{$(t_j^u)_{j=1,\ldots,J}$ from $\cD_{n_{train}}$}
      $\mathcal{X}_i = \Big(x_i, y_i, \big(\Psi_i(t_j^u)\big)_{j=1,\ldots,J}\Big)$ 
    }
    $\hat \cR_{i,\breve{r}} \leftarrow \texttt{model.predict}(\mathcal{X}_i)$
  }
  $\texttt{score}_{\breve{r}} \leftarrow \texttt{c\_index}\big((\hat \cR_{i,\breve{r}}, t_i, \delta_i)_{i=1,\ldots,n_{test}} \big)$ \\
  $\texttt{end\_time} = \texttt{time}()$ \\
  $\texttt{running\_time}_{\breve{r}} = \texttt{end\_time} - \texttt{start\_time}$ \\
}
\textbf{Return:} {$\big[\texttt{score}_{\breve{r}}\big]_{\breve{r}=1,\ldots,\breve{R}}\ , \ \big[\texttt{running\_time}_{\breve{r}}\big]_{\breve{r}=1,\ldots,\breve{R}}$}
\end{algorithm}

\begin{figure}[!htb]
\centering
\includegraphics[width=.3\textwidth]{./figures/beta_law.pdf}
\caption{Density of the law used to simulate $t_i^{max}$ to mimic the fact that in practice, one has access to a reasonable amount of longitudinal data before making a prediction.}
\label{fig:timax-pdf}
\end{figure}

\subsection{Competing models}
\label{sec:competing models}

In this section, we briefly introduce the models we consider for performance comparisons in the simulation study as well as in the applications on real datasets in Section~\ref{sec:application}. We also give the corresponding marker rule for each model, using our notations.

\paragraph*{Landmark Cox model.}

The first model we consider as a baseline is the well known Cox PH model with time-independent features, also known in the joint modeling context as the ``landmark'' model, in which we include basic time-independent features extracted from longitudinal processes and computed at the prediction time [REF].
In the Cox PH model introduced in \citet{Cox1972JRSS}, a parameter vector $\beta$ is estimated by minimizing the partial log-likelihood given by
\begin{equation*}
  \ell_n^{\text{cox}}(\beta) = n^{-1} \sum_{i=1}^n \delta_i \big( x_i^\top \beta - \log \sum_{i' : t_{i'} \geq t_i} \text{exp}(x_{i'}^\top \beta) \big).
\end{equation*}
For each time-dependant feature, we include subject-specific random effects, values of longitudinal processes at baseline and at time $t^{max}$, slope of longitudinal processes at time $t^{max}$ and area under of longitudinal processes from baseline up to $t^{max}$. The predictive marker for subject $i$ is the regular risk score~\citep{therneau2000cox}, that is $\hat \cR_i^{\text{cox}} = \exp (x_i^\top\hat\beta^{\text{cox}})$, with 
\[\hat\beta^{\text{cox}} \in \argmin_{\beta \in \R^\vartheta} -\ell_n^{\text{cox}}(\beta).\]
We use the \texttt{Python} package \texttt{tick} for the estimation of the previous quantity.
Ties are handled via the Breslow approximation of the partial likelihood \citep{breslow1972contribution}.

\paragraph*{Penalized Cox model.}

We then consider a penalized version of the Cox model, including now much more time-independent features automatically extracted from longitudinal processes using the \texttt{Python} package \texttt{tsfresh}~\citep{christ2018time}.
The predictive marker for the a subject $i$ is $\hat \cR_i^{\text{cox EN}} = \exp (x_i^\top\hat\beta^{\text{cox EN}})$, with 
\[\hat\beta^{\text{cox EN}} \in \argmin_{\beta \in \R^\vartheta} -\ell_n^{\text{cox}}(\beta) + \xi \big( (1-\eta)\norm{\beta}_1 + \frac{\eta}{2} \norm{\beta}_2^2 \big)\] 
the estimate obtained using elastic net penalization (still with the \texttt{tick} package), and
where $\xi$ is chosen by the a 10-fold cross-validation procedure, for a given $\eta \in [0, 1]$.

\paragraph*{The time-dependent Cox model.}

A classical extension of the Cox model supposes that features depend on time~\citep{sueyoshi1992semiparametric} (and then loosing the risk proportionality property), that is with our notations
\[\lambda_i(t) = \lambda_0(t) \exp\big(x_i^\top \gamma_0 + y_i(t_i^{max})^\top \beta \big). \]
We use the \texttt{survival} \texttt{R} package~\citep{zhang2018time}, and we consider the natural predictive marker for a subject $i$, that is the corresponding risk score given by
\[\hat \cR_i^\text{cox t-d} = \exp \big(x_i^\top \hat\gamma_0 + y_i(t)^\top \hat\beta \big).\] 

\paragraph*{Multivariate joint latent class model.} 

We consider a multivariate version of JLCMs implemented in the \texttt{R} package \texttt{lcmm}~\citep{2017_lcmm}.
Contrary to the lights model, there is no shared associations between the longitudinal models and the survival model. Given the latent class membership, each submodel is assumed to be independent. In this context, the predictive marker for subject $i$ is
\[\hat \cR_i^\text{lcmm} = \dfrac{\pi_{\hat \xi}(x_i) f(t^{max}_i, y_i | G_i=1 ; \hat \theta)}{\pi_{\hat \xi}(x_i) f(t^{max}_i, y_i | G_i=1 ; \hat \theta) + \big(1 - \pi_{\hat \xi}(x_i)\big) f(t^{max}_i, y_i | G_i=0 ; \hat \theta)}.\]

\paragraph*{Multivariate shared random effect model.}

In this context, we consider the \texttt{JMbayes} package~\citep{2017_JMbayes}. The predictive marker associated with this model for subject $i$ is naturally given by the corresponding risk score
\[\hat \cR_i^\text{JMbayes} = \exp \Big\{ x_i^\top \hat\gamma_0 + \sum_{l=1}^L \sum_{a=1}^\cA {\widehat{\gamma_{k,a}^l}}^\top \varphi_{k,a}(t_i^{max}, b_i^l) \Big\}.\] 

\texttt{@Antoine : est-ce qu'il peut prendre des time-indep feat ? et quelles sont les assos ?}


\section{High-dimensional simulation study}
\label{sec:simulation study}

In this section, we provide details regarding data generation, followed by the results of the extensive Monte Carlo simulation study to examine our method and compare it with state-of-the-art.

\subsection{Simulation design}
\label{simulation design}

In order to assess the proposed method, we run an extensive Monte Carlo simulation study in the case $K=2$ (see Section~\ref{sec:K=2}). We first choose a coefficient vector 
\begin{equation}
  \label{eq:xi-sparse}
  \xi = (\underbrace{\varsigma_1,\ldots,\varsigma_1}_s,0,\ldots,0) \in \R^p,
\end{equation} 
with $\varsigma_1\in\R$ being the value of the active coefficients and $s\in \{1,\dots,p\}$ a sparsity parameter chosen such that a proportion $r_s$ of time-independent features are actually active, that is $s = \lfloor p \times r_s \rfloor$. 
For a desired high-risk subjects proportion $\pi_1 \in [0,1]$, the high-risk subjects index set is given by
\[\cH = \big\{\lfloor \pi_1 n \rfloor \text{ random samples without replacement} \big\} \subset \{1, \ldots,n\}.\]
For the generation of the time-independent features matrix, we take 
\[ [x_{ij}] \in \R^{n \times p} \sim \cN \big(0, \bSigma_1(\rho_1)\big),\] 
with $\bSigma_1(\rho_1)$ a $(p \times p)$ Toeplitz covariance matrix \citep{mukherjee1988some} with correlation $\rho_1 \in (0, 1)$, that is $\bSigma_1(\rho_1)_{jj'} = \rho_1^{|j - j'|}$. 
We then add a $gap \in \R^+$ value for subjects $i \in \cH$ and subtract it for subjects $i \notin \cH$, only on active features, that is
\[x_{ij} \leftarrow x_{ij} + (-1)^{\ind{\{i \notin \cH\}}} gap\ \text{for } j = 1, \dots, s.\]
Note that this is equivalent to generate the time-independent features according to a gaussian mixture. We finally normalize each time-independent features for practical interpretations.
Then, we generate $G_i \sim \cB\big(\pi_\xi(x_i)\big)$, where $\pi_\xi(x_i)$ is computed given Equation~\eqref{eq:pi-softmax} and $\cB(\alpha)$ denotes the Bernoulli distribution with parameter $\alpha \in [0,1]$.

Now, concerning the simulation of the longitudinal data, the idea is to sample from multivariate normal distributions. 
We use linear time-varying features such that
\[ Y_i^l(t) = \sum_{k=0}^{K-1} \ind{\{G_i=k\}} \big( (1, t)^\top \beta_k^l + (1, t)^\top b_i^l + \epsilon_i^l(t) \big) \]
where $t \geq 0$, the error term $\epsilon_i^l(t) \sim \cN(0, \sigma_l^2)$, the global variance-covariance matrix for the random effects components~\eqref{eq:random-effect-law} is such that $D = \bSigma_2(\rho_2)$, a $(r \times r)$ Toeplitz covariance matrix with correlation $\rho_2 \in (0, 1)$, and the fixed effect parameters are generated according to 
\[ \beta_k^l \sim \cN\Big( 
\mu_k, 
\begin{bmatrix}
  \rho_3 & 0\\
  0 & \rho_3
\end{bmatrix} 
\Big) \]
for $k \in \{0, 1\}$ and with correlation $\rho_3 \in (0, 1)$, so that trajectories start on average higher for high-risk subjects ($G_i=1$), and with a higher slope than low-risk subjects ($G_i=0$). This choice makes sens regarding that for simplicity, we take joint association parameters being all positive, see~\eqref{eq:gamma-sparse}.

Most joint modeling simulation studies use fixed time points~\citep{hickey2018joinerml}, that is $n_i^l = n_i^{l'}$ and $t_{ij}^l = t_{ij}^{l'}$ for all $(l, l') \in \{1, \ldots, L\}^2$ and $j = 1, \ldots, n_i^l$ for a given subject $i$, but it does not reflect actual behavior in practice, since data measurements of the different longitudinal processes are barely done simultaneously. For this reason, the simulation of realistic longitudinal features is not trivial and we use Hawkes processes~\citep{hawkes1974cluster} with exponential kernels to generate measurement times, which is a family of counting process with an autoregressive intensity. 
Hawkes processes model self-exciting behavior, that is in our case, when the measurement of one longitudinal process makes future measurements of the process -- as well as those of others processes, in a multivariate way -- more likely to happen.
Namely, for a subject $i$, times $\{t_{ij}^l\}_{j \geq 1}$ for processes $l=1, \ldots, L$ are simulated using a multivariate Hawkes process $N_{it} = [N_{it}^1 \cdots N_{it}^L]$ with $t \geq 0$ and $N_{it}^l = \sum_{j \geq 1} \ind{\{t_{ij}^l \leq t\}}$. The process $N_{it}$ is a multivariate counting process, whose components $N_{it}^l$ have intensities
\[ \lambda_i^l(t) = \Upsilon_{l} + \sum_{l'=1}^L \sum_{j \geq 1} A_{ll'} \upsilon \exp\big(-\upsilon(t - t_{ij}^{l'}) \big) \]
for $l=1, \ldots, L$. $\Upsilon_{l} \geq 0$ is called baseline intensity, and corresponds to the exogenous probability of having a measurement for process $l$. We sample $\Upsilon_{l} \sim \cU\big([0.1,1]\big)$ ] which produces unbalanced baselines, where $\cU\big([a,b]\big)$ stands for the uniform distribution on a segment $[a,b]$.
The matrix $A = [A_{ll'}]_{1 \leq l,l' \leq L}$ is the adjacency matrix such that $A_{ll'} \geq 0$ quantifies the impact of past measurement time of process $l'$ on the measurement time of process $l$, and $\upsilon \geq 0$ is a memory parameter. We sample $A_{ll'} \sim \cU\big([0.1,0.2]\big)$, but then enforce $A$ to be sparse (with a chosen density of $0.3$) by randomly zeroing non-diagonal coefficients. Simulation of the Hawkes processes
is achieved using the \texttt{tick} library~\citep{bacry2017tick}. An example of simulated longitudinal features for an individual is displayed in Figure~\ref{fig:example-data} below. 

Now to generate survival times, we want to induce sparsity in the longitudinal data effects, so we set 
\[\cS_k=\Big\{ k \big\lfloor \dfrac{L r_s}{K} \big\rfloor + 1, \ldots,  (k + 1) \big\lfloor \dfrac{L r_s}{K} \big\rfloor \Big\}\] 
and we choose a risk model~\eqref{eq:intensity-model} with
\begin{equation*}
  \left\{
    \begin{array}{ll}
    \big(\varphi_{k,a}(t, b_i^l)\big)_{a \in \{1,2\}} = \big(\beta_{k,1}^l + \beta_{k,2}^l t + b_{i,1}^l + b_{i,2}^l t\ , {b_i^l}^\top \big)^\top \ind{\{l \in \cS_k\}} + \cN \big(0, \bSigma_3(\rho_3)\big) \ind{\{l \notin \cS_k\}}  \\
    \big( \varphi_{k,a}(t, b_i^l)\big)_{a=3,\ldots,\cA} = \cN \big(0, \bSigma_4(\rho_3)\big),
    \end{array}
  \right.
\end{equation*}

rmq : plus besoin du sk dans phi vu qu'on l'ajoute directement ds le Y non ?

and 
\begin{equation}
  \label{eq:gamma-sparse}
  \gamma_{k,a}^l = \varsigma_2 \mathbf{1}_{\imath_a} \ind{\big\{l \in \cS_k,\ a\in \{1, 2\} \big\}}
\end{equation}
for the choice of the association parameters, with $\cA = 3 + 3(1-r_s)/r_s$ so that $(i)$ there is a proportion $r_s$ of active longitudinal features among the $L$ (with the $\cS_k$), $(ii)$ we induce sparsity within each latent class adding a proportion of $(1-r_s)$ non-active association features ($a \geq 3$) in each latent class (similarly to~\eqref{eq:xi-sparse} for the time-independent features), and $(iii)$ the longitudinal effects are distinct for each latent class $k=0, \ldots, K-1$ (thanks to the $\cS_k$ definition).

In terms of active association features, it corresponds to~\eqref{eq:intensity-model} taking the first two functionals described in Table~\ref{table:shared_associations} as shared associations with $\alpha = 1$ in~\eqref{eq:alpha-def} so that one can write
\[ \lambda_i(t|G_i = k) = \lambda_0(t) \exp \big\{ \iota_{i,k,1} + \iota_{i,k,2} t \big\},\]
being a Cox model with a linear time-varying feature that allows the following explicit survival times generation process. Then, we do not consider the time-dependent slope as association feature since here with $\alpha = 1$, it would be collinear with the random effects.
We choose a Gompertz distribution~\citep{gompertz1825xxiv} for the baseline, that is
\begin{equation}
  \label{eq:baseline}
  \lambda_0(t) = \kappa_1 \kappa_2 \exp(\kappa_2t)
\end{equation}
with $\kappa_1 > 0$ and $\kappa_2 \in \R$ the scale and shape parameters respectively, which is a common distribution choice in survival analysis~\citep{klein2005survival} with a rich history in describing mortality curves. One can now generate survival times explicitly as
\begin{equation}
  \label{eq:time-generation}
  T_i^\star | G_i=k \sim \dfrac{1}{\iota_{i,k,2} + \kappa_2} \log \Big(1 - \dfrac{(\iota_{i,k,2} + \kappa_2) \log U_i}{\kappa_1 \kappa_2 \exp\iota_{i,k,1}} \Big)
\end{equation}
where $U_i \sim \cU\big([0,1]\big)$ (see Appendix~\ref{sec:event-time-simu} for the derivation of this expression).
The distribution of the censoring variable $C_i$ is the geometric distribution $\cG(\alpha_c)$, where $\alpha_c \in (0, 1)$ is empirically tuned to maintain a desired censoring rate $r_c \in [0,1]$. 
The choice of all hyper-parameters is driven by the applications on real data presented in Section~\ref{sec:application}, and summarized in Table~\ref{table:parameters choice}. Figure~\ref{fig:example-data} gives an example of data generated according to the design we have just described.
\begin{table}[htb]
\caption{Hyper-parameter choices for simulation. Let us also precise that we take $n \in [200, 4000]$ and $(p, L) \in [3, 300]^2$.
\label{table:parameters choice}}
\centering
\resizebox{\textwidth}{!}{
\begin{tabular}{cccccccccccc}
\toprule
$\pi_1$ & $(\rho_1, \rho_2, \rho_3)$ & $\mu_0$ & $\mu_1$ & $gap$ & $\sigma_l^2$ & $\upsilon$ & $(\kappa_1, \kappa_2)$ & $(\varsigma_1, \varsigma_2)$ & $r_c$ & $r_s$ & $\eta = \tilde{\eta}$ \\
\midrule
0.4 & $(, 10^{-3},)$ & 
$\begin{pmatrix}
  1 \\ 0.3
\end{pmatrix}$ & 
$\begin{pmatrix}
  1 \\ 0.5
\end{pmatrix}$ 
& 0.5 & 4 & 3 & $(10^{-3}, 0.1)$ & (1, 0.1) & 0.3 & 0.4 & 0.1 \\
\bottomrule
\end{tabular}}
\end{table}
\begin{figure}[!htb]
\centering
\subfigure[blabla]{
% \includegraphics[width=.3\textwidth]{./figures/beta_law.pdf}
\label{fig:yoyo}}
\hspace{.02\textwidth}
\subfigure[exemple simu]{
% \includegraphics[width=.38\textwidth]{./figures/time2.pdf}
\label{fig:example-data}}
\caption{Illustrations of simulated data.}
\end{figure}

Following the real-time prediction paradigm presented in Section~\ref{sec:evaluation strategy}, we compare the predictive performances of the lights model with the competing ones introduced in Section~\ref{sec:competing models} in terms of C-index (see Section~\ref{sec:evaluation strategy}).
We also want to assess the stability of the lights model in terms of feature selection, but we do not compare this aspect with state-of-the-art since other models are not designed to perform feature selection, and comparisons would be unfair. 
To this end, we follow the same simulation procedure explained in the previous lines and for each simulation case, we use the following approach to evaluate the variable selection power of the model. Denoting 
\[\tilde{\xi}_j = \dfrac{|\hat{\xi}_j|}{\max_{j=1,\ldots,p}{|\hat{\xi}_j|}} \qquad \text{and} \qquad \tilde{\gamma}_{k,a}^l = \dfrac{|\hat{\gamma}_{k,a}^l|}{\max_{a=1, \ldots, \cA}{|\hat{\gamma}_{k,a}^l|}}\] 
for $k=0,\ldots,K-1$ and $l=1, \ldots, L$, and considering that $\tilde{\xi}_j$ and $\tilde{\gamma}_{k,a}^l$ are the predicted probability that the true $\xi_j$ equals $\varsigma_1$ and the predicted probability that the true $\gamma_{k,a}^l$ equals $\varsigma_2$ respectively, then we are in a binary prediction setting and we use the two resulting AUC scores of this problem to evaluate the selection power of the time-independent and the time-dependent features respectively.

\subsection{Results of simulation}
\label{sec:simulation results}
Let us present now the simulation results.


\section{Applications}
\label{sec:application}

In this section, we apply our lights method on two publicly available datasets and compare its performance with state-of-the-art methods.

\subsection{The PBCseq dataset}

This dataset is a follow-up to the original dataset~\citep{fleming2011counting, murtaugh1994primary}from the Mayo Clinic trial in primary biliary cirrhosis (PBC) of the liver conducted between 1974 and 1984. 
A total of 424 PBC patients, referred to Mayo Clinic during that ten-year interval, met eligibility criteria for the randomized placebo controlled trial of the drug D-penicillamine. The first 312 cases in the data set participated in the randomized trial and contain largely complete data. The additional 112 cases did not participate in the clinical trial, but consented to have basic measurements recorded and to be followed for survival. Six of those cases were lost to follow-up shortly after diagnosis, so the data here are on an additional 106 cases as well as the 312 randomized participants. 
The dataset contains only baseline measurements of the laboratory paramters and contains multiple laboratory results, but only on the first 312 patients. 


\subsection{The MIMIC III dataset}

The MIMIC III (Medical Information Mart for Intensive Care III) database is a large, freely-available hospital dataset containing de-identified data from over 40,000 patients. This data comes from patients who were admitted in critical care units to Beth Israel Deaconess Medical Center in Boston, Massachusetts from 2001 to 2012~\citep{johnson2016mimic}. The dataset was populated with data that had been acquired during routine hospital care, so there was no associated burden on caregivers and no interference with their workflow.

% \url{https://www.nature.com/articles/sdata201635/}\\
% \url{https://ieeexplore.ieee.org/abstract/document/1166854}\\
% \url{https://www.sciencedirect.com/science/article/abs/pii/S2213260014702395}\\
% \url{https://www.sciencedirect.com/science/article/pii/S2352556818302169}\\
% }


\section{Conclusion}
\label{sec:conclusion}

In this paper, a generalized joint model for high-dimensional multivariate longitudinal data and censored durations (lights) has been introduced, and a new efficient estimation
algorithm (prox-QNEM) has been derived, that considers a penalization of the likelihood in order to perform feature
selection and to prevent overfitting.


\section*{Software}
All the methodology discussed in this paper is implemented in \texttt{Python}. The code is available from \url{https://github.com/Califrais/lights} in the form of annotated programs, together with a notebook tutorial. A technical documentation is also provided in Appendix~\ref{sec:package}.

\section*{Acknowledgements}
\textit{Conflict of Interest}: None declared.

\appendix

\begin{center}
\LARGE \textbf{Appendices}
\end{center}

\section{Proof of Lemma~\ref{lemma:prox-sgl1}}
\label{sec:proof-lemma-prox-sgl1}

The proximal operator~\citep{moreau1962fonctions} for any function $f : \R^p \to \R$ is defined by
\begin{equation}
    \label{eq:prox-def}
    \text{prox}_{f}(u) = \argmin_{x \in \R^p} \big\{\frac{1}{2}\norm{x - u}_2^2 + f(x)\big\}.
\end{equation}
To prove Lemma~\ref{lemma:prox-sgl1}, we need to show that
\[\text{prox}_{\lambda_1 \norm{\cdot}_1 + \lambda_2 \sum_{l=1}^L  \norm{\cdot}_{2,l}} = \text{prox}_{\lambda_2 \sum_{l=1}^L \norm{\cdot}_{2,l}} \circ \text{prox}_{\lambda_1 \norm{\cdot}_1}\]
where $\text{prox}_{\lambda_1 \norm{\cdot}_1 + \lambda_2 \sum_{l=1}^L \norm{\cdot}_{2,l}}$ is the proximal operator for the sparse group lasso regularizer, $\text{prox}_{\lambda_2 \sum_{l=1}^L \norm{\cdot}_{2,l}}$ is the proximal operator for the group lasso regularizer and $\text{prox}_{\lambda_1 \norm{\cdot}_1}$ is the proximal operator for the lasso regularizer. $\lambda_1 > 0$ and $\lambda_2 > 0$ are regularization parameters, and $\norm{\cdot}_{2,l}$ denotes the Euclidean norm on features in the $l$-th group.

\begin{proof}
Fix any $\beta \in \R^p$ and denote 
\begin{equation*}
    k_\beta(x) =  \frac{1}{2}\norm{ x - \text{prox}_{\lambda_1 \norm{\cdot}_1}(\beta)}_2^2 + \lambda_2 \sum_{l=1}^L \norm{x}_{2,l}
\end{equation*}
for all $x \in \R^p$. Given that $\big(\text{prox}_{\lambda_1 \norm{\cdot}_1}(\beta)\big)_j=\max(0, 1-\lambda_1/|\beta_j|)\beta_j$~\citep{bach2011optimization}, $k_\beta$ is clearly strictly convex. Denoting $x^\star$ its unique minimizer,~\eqref{eq:prox-def} entails 
\[\text{prox}_{\lambda_2 \sum_{l=1}^L \norm{\cdot}_{2,l}}\big(\text{prox}_{\lambda_1 \norm{\cdot}_1}(\beta)\big) = \argmin_{x \in \R^p} k_\beta(x) = \{x^\star\}.\]
Then, it follows that
\begin{equation}
    \label{eq:opt_gl}
    0 \in \partial k_\beta(x^\star) = x^\star - \text{prox}_{\lambda_1 \norm{\cdot}_1}(\beta) + \partial\big( \lambda_2 \sum_{l=1}^L \norm{x^\star}_{2,l}\big)
\end{equation}
where $\partial k$ denotes the subgradient~\citep{rockafellar1974} of $k$.
Now denoting
\[h_\beta(x) = \frac{1}{2}\norm{x - \beta}_2^2 + \lambda_1 \norm{x}_1 + \lambda_2 \sum_{l=1}^L \norm{x}_{2,l} \] 
for all $x \in \R^p$ such that
\[\text{prox}_{\lambda_1 \norm{\cdot}_1 + \lambda_2 \sum_{l=1}^L \norm{\cdot}_{2,l}}(\beta) = \argmin_{x\in \R^p} h_\beta(x),\]
it remains to be proved that $0 \in \partial h_\beta(x^\star)$.

Then, it turns out that 
\[ \partial h_\beta(x) = x - \beta + \lambda_1 \text{SGN}(x) + \partial( \lambda_2 \sum_{l=1}^L \norm{x}_{2, l})\]
for all $x \in \R^p$, where SGN($x$) is the subgradient of the $\ell_1$-norm at $x$~\citep{bach2011optimization} defined in a component wise fashion as
\[\text{SGN}(x) = 
\left\{
  \begin{array}{ll}
    \{1\} &\text{if } x > 0, \\ 
    $[-1, 1]$ &\text{if } x = 0, \\ 
    \{-1\} &\text{if } x < 0. 
  \end{array}
\right. \]
Denoting $y = \text{prox}_{\lambda_1\norm{\cdot}_1}(\beta)$, Lemma 1.4) in~\citet{yuan2011efficient} entails $\text{SGN}(y) \subseteq \text{SGN}(x^*)$. Hence,
\[ y = \argmin_{u \in \R^p} \big\{\frac{1}{2} \norm{u - \beta}_2^2 + \lambda_1 \norm{u}_1\big\} 
    = \beta - \lambda_1 \text{SGN}(y) \subseteq \beta - \lambda_1 \text{SGN}(x^*), \]
which gives
\[0 \in x^\star - y + \partial( \lambda_2 \sum_{l=1}^L \norm{x^\star}_{2, l} ) \subseteq x^\star- \beta + \lambda_1 \text{SGN}(x^\star) + \partial( \lambda_2 \sum_{l=1}^L \norm{x^\star}_{2, l} ).\]
\end{proof}

\section{Automatic cross-validation grid for $\xi$}
\label{sec:auto-grid-cv}

Concerning the cross-validation procedure for tuning 
\[(\zeta_{1,0}, \zeta_{2,0}, \ldots, \zeta_{1,K-1}, \zeta_{2,K-1})^\top \in \R_+^{2K}, \]
we use a randomized search with the C-index metric (see Section~\ref{sec:evaluation strategy}) where for all $k=0, \ldots, K-1$ and $j \in \{1, 2\}$, each $\zeta_{j,k}$ finds its candidates in the interval 
\[[\zeta_{j,k}^{\text{max}} \times 10^{-4}, \zeta_{j,k}^{\text{max}} ] \subset \R, \]
with $\zeta_{j,k}^{\text{max}}$ the interval upper bound computed hereafter.

Considering the convex minimization problem~\eqref{eq:minimization-xi_k} at a given step $w$,
let us denote $\zeta_{1,k}^1 \leq \zeta_{1,k}^2 \leq \dots \leq \zeta_{1,k}^{\text{max}}$ the randomly chosen candidate values for $\zeta_{1,k}$, such that at $\zeta_{1,k}^{\text{max}}$, all coefficients $\hat \xi_{k, j}$ for all $j = 1, \dots, p$ are exactly zero.
The KKT conditions~\citep{boyd2004convex} claim that
\begin{center}
  $\left\{
      \begin{aligned}
        &\frac{\partial P_{n, k}^{(w)}(\hat \xi_k)}{\partial \xi_{k,j}} =  \zeta_{1,k} \big( (\eta-1)\ \text{sgn}(\hat \xi_{k,j}) - \eta \hat \xi_{k,j} \big)  \quad \ \ \ \forall j \in \hat \cA_k \\
        &\left| \frac{\partial P_{n, k}^{(w)}(\hat \xi_k)}{\partial \xi_{k,j}} \right| < \zeta_{1,k} (1 - \eta) \quad \quad \quad \quad \quad \quad \quad \ \forall j \notin \hat \cA_k
      \end{aligned}
    \right.$,
\end{center}
where $\hat \cA_k = \big\{j = 1, \dots, p : \hat \xi_{k,j} \neq 0 \big\}$ is the active set of the $\hat \xi_k $ estimator, and for all $x \in~\R\setminus~\{0\},\ \text{sgn}(x) = \mathds{1}_{\{x>0\}} - \mathds{1}_{\{x<0\}} $. Then, using~\eqref{eq:grad-xi_k}, one obtains
\begin{equation*}
\hat \xi_{k, j} = 0 \ \Rightarrow \ \left| n^{-1} \sum_{i=1}^n \pi_{ik}^{\theta^{(w)}} \big( 1 - \pi_{\xi_k}(x_i) \big) x_{ij}  \right| < \zeta_{1,k} (1 - \eta)
\end{equation*}
for all $j = 1, \dots, p$.
Hence, we choose the following upper bound for the randomly chosen candidate interval during the cross-validation procedure
\begin{equation*}
\zeta_{1,k}^{\text{max}} = \frac{1}{n(1-\eta)} \underset{j = 1, \dots, p}{\text{max}} \sum_{i=1}^n |x_{ij}|.
\end{equation*}
Similar strategy to automatically compute $\zeta_{2,k}^{\text{max}}$ is not easy since without additionnal hypothesis, the gradients~\ref{eq:grad-beta_k} and~\ref{eq:grad-Q} are not upper bounded by a quantity that depends only on the data and not on the current iteration parameters estimates. We then choose those interval upper bounds empirically.

\section{Event time simulation}
\label{sec:event-time-simu}

Let us derive here the expression~\eqref{eq:time-generation} used to generate event times. Indeed, we can not refer to~\citet{austin2012generating} since the intensity~\eqref{eq:baseline} of the baseline is not correct in this paper.
Note that other errors had already been pointed in~\citep{austin2013correction}, for instance the fact that there is no closed-form expression with a Weibull baseline.
Suppose that
\[\lambda(t) = \lambda_0(t) \exp (a + b t)\]
with $(a, b) \in \R^2$ and $\lambda_0$ defined in~\eqref{eq:baseline}, then the cumulative hazard function writes
\[H(t) = \kappa_1 \kappa_2 e^a \int_0^t \exp\{(\kappa_2 + b)s \} \dd s = \dfrac{\kappa_1 \kappa_2 e^a}{\kappa_2 + b} \big( \exp\{(\kappa_2 + b) t\} - 1 \big).\]
Then, on has
\[t = \dfrac{1}{\kappa_2 + b} \log \Big( 1 + \dfrac{H(t)(\kappa_2 + b)}{\kappa_1 \kappa_2 e^a} \Big),\]
and one can generate event times according to
\[ T \sim \dfrac{1}{\kappa_2 + b} \log \Big( 1 - \dfrac{(\kappa_2 + b)\log U}{\kappa_1 \kappa_2 e^a} \Big) \]
with $U \sim \cU\big([0,1]\big)$.
$\hfill\square$

\section{Multivariate linear mixed model}
\label{sec:MLMM}

Let us derive here the explicit EM algorithm for the multivariate linear mixed model used to initialized the longitudinal parameters $\beta_k^{(0)}$, $D^{(0)}$ and $\phi^{(0)}$ in the prox-QNEM algorithm in Section~\ref{sec:prox-QNEM}, acting as if there is no latent classes ($\beta_0^{(0)} = \cdots = \beta_{K-1}^{(0)}$).
For the sake of simplicity, let us denote here 
\[\theta = (\beta^\top, \text{vech}(D), \phi^\top)^\top \in \R^\vartheta\]
the parameter vector to infer.
The conditional distribution of $y_i|b_i$ then writes
\[f(y_i|b_i ; \theta) = \exp \big\{( \Sigma_iy_i)^\top M_{i} - c_\phi(M_{i}) + d_\phi(y_i) \big\},\]
where $\Sigma_i$ is the diagonal matrix whose diagonal is $\Phi_i$. 
The complete log-likelihood in this context writes
\begin{align*}
\ell_n^\text{comp}(\theta) &= \ell_n^\text{comp}(\theta ; \cD_n, \textbf{\textit{b}}) \\
&= \sum_{i=1}^n (\Sigma_iy_i)^\top M_{i} - c_\phi(M_{i}) + d_\phi(y_i) -\dfrac12 \big(r \log 2\pi + \log|D| + b_i^\top D^{-1}b_i\big).
\end{align*}
  
\paragraph*{E-step.}
Supposing that we are at step $w + 1$ of the algorithm, with current iterate denoted $\theta^{(w)}$, we need to compute the expected negative log-likelihood of the complete data conditional on the observed data and the current estimate of the parameters, which is given by 
\[\cQ_n(\theta, \theta^{(w)}) = \E_{\theta^{(w)}}[\ell_n^\text{comp}(\theta) | \cD_n].\]
Here, computing this quantity reduces to computing $\E_{\theta^{(w)}}[b_i | y_i]$ and $\E_{\theta^{(w)}}[b_ib_i^T | y_i]$ for $i = 1,\ldots,n$.
The marginal distributions of $y_i$ and $b_i$ being both Gaussian, one has from Bayes Theorem
\[ f(b_i|y_i; \theta^{(w)}) \propto \exp \big\{ -\dfrac12 (b_i - \mu_i^{(w)})^\top {\Omega_i^{(w)}}^{-1} (b_i - \mu_i^{(w)}) \big\}\]
where
\[\Omega_i^{(w)} = ({V_i}^\top \Sigma_i^{(w)}V_i + {D^{(w)}}^{-1})^{-1} \quad \text{ and } \quad \mu_i^{(w)} = \Omega_i^{(w)}{V_i}^\top \Sigma_i^{(w)}(y_i - U_i\beta^{(w)}).\]
Then, on has
\begin{center}
  $\left\{
    \begin{aligned}
      &\E_{\theta^{(w)}}[b_i | y_i] = \mu_i^{(w)}, \\
      &\E_{\theta^{(w)}}[b_ib_i^T | y_i] = \Omega_i^{(w)} + \mu_i^{(w)}{\mu_i^{(w)}}^\top.
    \end{aligned}
    \right.$
\end{center}

\paragraph*{M-step.}
Here, we need to compute \[\theta^{(w+1)} \in \argmin_{\theta \in \R^\vartheta} \cQ_n(\theta, \theta^{(w)}) .\]
The parameters updates are then naturally given in closed form by zeroing the gradient. One obtains
\[\beta^{(w+1)} = \Big(\sum_{i=1}^n U_{i}^\top U_{i}\Big)^{-1}  \sum_{i=1}^n \big[ U_{i}^\top  y_i - U_{i} V_{i} \E_{\theta^{(w)}}[ b_i | y_i]) \big],\]
\begin{align*}
\phi_l^{(w+1)} = \big(\sum_{i=1}^n n_i^l \big)^{-1}  \sum_{i=1}^n \Big[(&y_i^l - U_{il}\beta_l^{(w+1)})^\top (y_i^l - U_{il}\beta_l^{(w+1)} - 2V_{il}\E_{\theta^{(w)}}[b_i^l | y_i^l])) \\
&+\Tr\big(V_{il}^\top V_{il} \E_{\theta^{(w)}}[ b_i^l {b_i^l}^\top | y_i^l]\big) \Big]
\end{align*}
and \[D^{(w+1)} = n^{-1} \sum_{i=1}^n \E_{\theta^{(w)}}[ b_i {b_i}^\top | y_i].\]


\section{Technical documentation of the \texttt{lights} package}
\label{sec:package}

\subsection{\texttt{MLMM class}}
\label{sec:MLMM class}

This class implements an EM algorithm for fitting a multivariate linear mixed model used to initialize the QNEM algorithm.
Let us introduce the list $\Omega^{(w)} = [\Omega_1^{(w)}, \ldots, \Omega_n^{(w)}]$, the matrices $\mu = [\mu_1, \ldots, \mu_n] \in \R^{r \times n}$, $U^l = [{U_{1l}}^\top \cdots {U_{nl}}^\top]^\top \in \R^{n_l \times q_l}$, $U = [U_1^\top \cdots U_n^\top]^\top \in \R^{\cN \times q}$,
\[ V^l = \begin{bmatrix}
    V_{1l} & \cdots & 0\\
    \vdots &  \ddots & \vdots \\
    0 & \cdots & V_{nl}
\end{bmatrix},
\quad
V = \begin{bmatrix}
  V_{1} & \cdots & 0\\
  \vdots &  \ddots & \vdots \\
  0 & \cdots & V_{n}
\end{bmatrix}
\quad \text{ and } \quad
{\Omega^l}^{(w)} = \begin{bmatrix}
    {\Omega_{1}^l}^{(w)} & \cdots & 0\\
    \vdots &  \ddots & \vdots \\
    0 & \cdots & {\Omega_{n}^l}^{(w)}
\end{bmatrix}\]
that belong respectively in $\R^{n_l \times nr_l}$, $\R^{\cN \times nr}$ and $\R^{nr_l \times nr_l}$, as well as the vectors $\tilde \mu^{(w)} = ({\mu_1^{(w)}}^\top \cdots {\mu_n^\top)^{(w)}}^\top \in \R^{nr}$, $(\tilde \mu^l)^{(w)} = \big({(\mu_1^l)^{(w)}}^\top \cdots {(\mu_n^l)^{(w)}}^\top \big)^\top \in \R^{nr_l}$, $y^l = ({y_1^l}^\top  \cdots {y_n^l}^\top)^\top \in \R^{n_l}$
with $n_l = \sum_{i=1}^{n} n_i^l$ and $y = (y_1^\top \cdots y_n^\top)^\top \in \R^\cN$ with $\cN = \sum_{i=1}^{n} n_i$.
The $\beta$ update then rewrites
\[\beta^{(w+1)} = ({U}^\top U)^{-1}{U}^\top(y-V \tilde \mu^{(w)}).\]
For the $D$ update, one has
\[D^{(w+1)} = n^{-1} \big( \text{sum}(\Omega^{(w)}) + \mu^{(w)}{\mu^{(w)}}^\top\big).\]
And finally for the $\phi$ update, one has
\begin{align*}
\phi_l^{(w+1)} = n_l^{-1} \big[&(y^l - U^l{\beta_l^{(w+1)})}^\top \big(y^l - U^l\beta_l^{(w+1)} - 2 V^l (\tilde\mu^l)^{(w)}\big) \\
&+ \text{Tr}\big\{{V^l}^\top V^l \big({\Omega^l}^{(w)} + (\tilde\mu^l)^{(w)} {(\tilde\mu^l)^{(w)}}^\top\big)\big\} \big].
\end{align*}

\subsection{\texttt{prox-QNEM class}}
\label{sec:prox-QNEM class}

Let us introduce the following useful notations
\begin{equation*}
  \left\{
    \begin{array}{ll}
    \tilde g^1&: b_i \mapsto b_i,\\
    \tilde g^2&: b_i \mapsto b_ib_i^\top.
    \end{array}
  \right. 
\end{equation*}


\bibliography{biblio}
\bibliographystyle{plainnat}{}
\end{document}
